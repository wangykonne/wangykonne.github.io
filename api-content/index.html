{"posts":[{"title":"萌新编程题实战（持续更新）","content":" 我太菜了，做得又慢又复杂Orz 字节-房间题 题目描述 有n个房间，现在i号房间里的人需要被重新分配，分配的规则是这样的：先让i号房间里的人全都出来，接下来按照 i+1, i+2, i+3, ... 的顺序依此往这些房间里放一个人，n号房间的的下一个房间是1号房间，直到所有的人都被重新分配。现在告诉你分配完后每个房间的人数以及最后一个人被分配的房间号x，你需要求出分配前每个房间的人数。数据保证一定有解，若有多解输出任意一个解。 输入描述 第一行两个整数n, x (1&lt;=x&lt;=n)，代表房间房间数量以及最后一个人被分配的房间号； 第二行n个整数aia_iai​ ，代表每个房间分配后的人数。 输出描述 输出n个整数，代表每个房间分配前的人数。 示例 输入： 3 1 6 5 1 输出： 4 4 4 思路与解答 我的想法是从末状态进行倒推，从x位置-1然后到x-1位置再-1。而终止情况就是在某个位置人数-1之后，其前一个位置的人数恰好为0，此时刚好说明回到了原始状态。代码如下： information = input().split() n = int(information[0]) x = int(information[1]) n_number = input().split() a = [int(n_number[i]) for i in range(len(n_number))] i = 0 #反向移动函数 def move(m): if m != 1: m -= 1 else: m = n return m #倒推到初始情况 while a[x-1] != 0: a[x-1] -= 1 x = move(x) i += 1 #补上人被清空的初始房间 a[x-1] = i result = '' for i in range((len(a))-1): result += str(a[i])+' ' print(result+str(a[-1])) 字节-移动房间题 题目描述 存在n+1个房间，每个房间依次为房间1 2 3...i，每个房间都存在一个传送门，i房间的传送门可以把人传送到房间pi(1&lt;=pi&lt;=i),现在路人甲从房间1开始出发(当前房间1即第一次访问)，每次移动他有两种移动策略：A. 如果访问过当前房间 i 偶数次，那么下一次移动到房间i+1；B. 如果访问过当前房间 i 奇数次，那么移动到房间pi；现在路人甲想知道移动到房间n+1一共需要多少次移动； 输入描述 第一行包括一个数字n，表示房间的数量，接下来一行存在n个数字 pi(1&lt;=pi&lt;=i), pi表示从房间i可以传送到房间pi。 输出描述 输出一行数字，表示最终移动的次数。 示例 输入： 2 1 2 输出： 4 说明：开始从房间1只访问一次所以只能跳到p1即房间1， 之后采用策略A跳到房间2，房间2这时访问了一次因此采用策略B跳到p2房间即房间2，之后采用策略A跳到房间3，因此到达房间3需要4步操作。 思路与解答 我的想法比较简单粗暴，用一个list-at储存下路人的移动轨迹，但移动到n+1时停止。同时写一个函数num(i)来表示路人目前到i房间多少次了，而有移动轨迹at的话这个计数只要比对at=i的次数就可以了。代码如下： n = int(input()) pi = input().split() at = [1] #访问房间i的次数函数 def num(i): k = 0 for j in range(len(at)): if at[j]==i: k+=1 return k step = 0 #随移动更新轨迹at，到n+1房间停止 while at[step]!=(n+1): if num(at[step])%2 == 1: at.append(int(pi[at[step]-1])) else: at.append(at[step]+1) step+=1 print(step) 字节-片段字符串长度题 题目描述 有一个仅包含’a’和’b’两种字符的字符串s，长度为n，每次操作可以把一个字符做一次转换（把一个’a’设置为’b’，或者把一个’b’置成’a’)；但是操作的次数有上限m，问在有限的操作数范围内，能够得到最大连续的相同字符的子串的长度是多少？ 输入描述 第一行两个整数 n , m，第二行为长度为n且只包含’a’和’b’的字符串s。 输出描述 输出在操作次数不超过 m 的情况下，能够得到的 最大连续 全’a’子串或全’b’子串的长度。 示例 输入： 8 1 aabaabaa 输出： 5 说明：把第一个 'b' 或者第二个 'b' 置成 'a'，可得到长度为 5 的全 'a' 子串。 思路与解答 首先分析需要什么功能，显然需要一个函数能返回一个字符串中最长片段a或b的长度，正巧之前学了点正则表达式，所以可以用正则表达式取出字符串中所有的a片段或b片段，返回最长片段的长度。其次，需要变化ab若干，不管变化多少次都可以用1次递归，所以我写了个函数change1(string,i)表示将string的第i个位置的a变为b或b变为a，返回变换后的新字符串。 解这道题的思路类似贪心算法——每次变换达到最大长度的字符串保留为新字符串然后继续递归执行m次（虽然每一步最优不一定合起来就是总体最优，但这道题貌似就是总体最优），有上面这两个函数，以变换一次为例，可以找到变换一次能达到的最长片段长度和对应的新字符串，然后递归m次，用序列储存m次变换对应的长度，取最大值即可。代码如下： import re npm = input().split() n = int(npm[0]) m = int(npm[1]) abstr = input() #计算最大片段长度 def count(string): resulta = re.findall('[a]+',string) resultb = re.findall('[b]+',string) la = [len(resulta[i]) for i in range(len(resulta))] lb = [len(resultb[i]) for i in range(len(resultb))] return max(max(la),max(lb)) #得到变换i位置后的新字符串 def change1(string,i): l = list(string) if l[i]=='a': l[i] = 'b' else: l[i] = 'a' return ''.join(l) ans = [0 for i in range(m)] j = 0 #每次变换更新能得到最大片段长的新字符串为abstr进行下一轮循环 while j&lt;=(m-1): length = [count(change1(abstr,i)) for i in range(n)] ans[j] = max(length) maxindex = sorted(range(len(length)), key=lambda k: length[k], reverse=True)[0] abstr = change1(abstr, maxindex) j+=1 print(max(ans)) ","link":"https://wangykonne.github.io/post/meng-xin-bian-cheng-ti-shi-zhan-chi-xu-geng-xin/"},{"title":"集成算法理论简介","content":" bagging和boosting 所谓的集成学习算法，就是用多重或多个弱分类器结合为一个强分类器，从而达到提升分类方法效果。严格来说，集成学习并不算是一种分类器，而是一种分类器结合的方法。集成学习分为两种方法：①bagging；②boosting。 bagging bagging的基本流程如下： 原始数据集通过T次随机采样（一般是有放回的），得到T个与原始数据集相同大小的子数据集，分别训练得到T个弱分类器Classifier，然后结合为一个强分类器。比如随机森林，就是一种决策树的bagging算法，需要注意的是，随机森林训练T个弱分类器Classifier的过程一般并不会使用数据集的全部特征，而是随机选择一些特征，从而能防止过拟合。最后把T个弱分类器Classifier集成为强学习器的vote方法比较简单，对于一个测试样本，通过T个弱分类器得到T个类别信息，这些信息投票产生最后的类别。如T=10，分类结果分别为：[3,3,3,3,5,5,6,7,1,8]那么这个样本就属于3. 随机森林 随机森林，顾名思义，是用随机的方式建立一个森林，森林里面有很多的决策树组成，随机森林的每一棵决策树之间是没有关联的。在得到森林之后，当有一个新的输入样本进入的时候，就让森林中的每一棵决策树分别进行一下判断，看看这个样本应该属于哪一类（对于分类算法），然后看看哪一类被选择最多，就预测这个样本为那一类。 在建立每一棵决策树的过程中，有两点需要注意：采样与完全分裂。首先是两个随机采样的过程，randomforest对输入的数据要进行行、列的采样。对于行采样，采用有放回的方式，也就是在采样得到的样本集合中，可能有重复的样本。假设输入样本为N个，那么采样的样本也为N个。这样使得在训练的时候，每一棵树的输入样本都不是全部的样本，使得相对不容易出现over-fitting。然后进行列采样，从M个feature中，选择m个(m &lt;&lt; M)。之后就是对采样之后的数据使用完全分裂的方式建立出决策树，这样决策树的某一个叶子节点要么是无法继续分裂的，要么里面的所有样本的都是指向的同一个分类。一般很多的决策树算法都一个重要的步骤：剪枝，但是这里不这样干，由于之前的两个随机采样的过程保证了随机性，所以就算不剪枝也不会出现overfitting。 按这种算法得到的随机森林中的每一棵都是很弱的，但是所有树组合起来就是强分类器了。可以这样比喻随机森林算法：每一棵决策树就是一个精通于某一个窄领域的专家（因为我们从M个feature中选择m让每一棵决策树进行学习），这样在随机森林中就有了很多个精通不同领域的专家，对一个新的问题（新的输入数据），可以用不同的角度去看待它，最终由各个专家，投票得到结果。 boosting 类似于bagging集成学习，boosting也是通过重采样得到多个弱分类器，最后得到一个强分类器。区别是boosting是基于权值的弱分类器集成。 如上图为boosting的流程图，主要为两个部分，更新采样权值D和计算分类器权重α\\alphaα，前者使得原来分错的样本再下一个分类器中能够有较大的几率出现，从而提高原来分错样本之后分对的概率；后者根据分类器的表现，赋予不同弱分类器不同权值，最后得到一个加权的强分类器。经过不断地迭代更新能使得最终的结果无限接近最优分类，不过boosting会倾向于一直分错的样本，如果样本中有离群的错误样本，boosting就会出现效果不好的情况。 Adaboost AdaBoost，是英文&quot;Adaptive Boosting&quot;（自适应增强）的缩写，由Yoav Freund和Robert Schapire在1995年提出。它的自适应在于：前一个基本分类器分错的样本会得到加强，加权后的全体样本再次被用来训练下一个基本分类器。同时，在每一轮中加入一个新的弱分类器，直到达到某个预定的足够小的错误率或达到预先指定的最大迭代次数。 具体说来，整个Adaboost 迭代算法就3步： ①初始化训练数据的权值分布。如果有N个样本，则每一个训练样本最开始时都被赋予相同的权值：1N\\frac{1}{N}N1​。 ②训练弱分类器。具体训练过程中，如果某个样本点已经被准确地分类，那么在构造下一个训练集中，它的权值就被降低；相反，如果某个样本点没有被准确地分类，那么它的权值就得到提高。然后，权值更新过的样本集被用于训练下一个分类器，整个训练过程如此迭代地进行下去。 ③将各个训练得到的弱分类器组合成强分类器。各个弱分类器的训练过程结束后，加大分类误差率小的弱分类器的权重，使其在最终的分类函数中起着较大的决定作用，而降低分类误差率大的弱分类器的权重，使其在最终的分类函数中起着较小的决定作用。换言之，误差率低的弱分类器在最终分类器中占的权重较大，否则较小。 二者的区别 二者的主要区别是取样方式不同。Bagging采用均匀取样，而Boosting根据错误率来取样，因此Boosting的分类精度要优于Bagging。Bagging的训练集的选择是随机的，各轮训练集之间相互独立，而Boosting的各轮训练集的选择与前面各轮的学习结果有关；Bagging的各个预测函数没有权重，而Boosting是有权重的；Bagging的各个预测函数可以并行生成，而Boosting的各个预测函数只能顺序生成。对于象神经网络这样极为耗时的学习方法。Bagging可通过并行训练节省大量时间开销。bagging和boosting都可以有效地提高分类的准确性。在大多数数据集中，boosting的准确性比bagging高。 ","link":"https://wangykonne.github.io/post/ji-cheng-suan-fa-li-lun-jian-jie/"},{"title":"无题","content":" 自觉心境已有如明镜，为何为天降的稀客泛过一点浪花 可能是春天来了，万物生长。自己最近对谈恋爱的渴望上升到了前几年都没有的水平上...以前，从没有谈过恋爱的小王经常用“自己一个人也很充实快乐啊干嘛要找对象”来逃避，只是最近这招似乎不那么管用了。“肯定是不够充实，把时间表都填满就不会瞎想些有的没的了”，于是小王决定过一个最充实的周末：早上自然醒然后学习，中午吃饭刷B站，下午午睡然后去跑步回来洗澡再学习一会吃饭，晚上拉同学一起打游戏。“你看，还需要女朋友吗？”躺在床上小王这样想，然而这次却没得出肯定的回答。“一定少了些什么”，他想，确实，他去问了问发小，得到的回答是“就差把想谈恋爱写在脸上了”😅 可惜，自己性格太自闭了，连我自己都想不到脱单的方法，或许真得等相亲了。但相亲是不是谈恋爱呢？至少目前我持怀疑态度。 不过最近感觉喜欢上了一个女生，慢热的我好像四五年都没喜欢上一个女生了...然而都不知道妹子有无男朋友，当初看到情头差点就脱战了，要真有男朋友估计又要自闭了😓唉，回想每次暗恋女生最后都没得到什么好结果，反倒经常把自己心态搞崩戴上痛苦面具。自己的青春就只有“我本将心向明月，奈何明月照沟渠”的故事，时也？命也？ 3.14：再次自闭，喜欢一个人太累了，爷溜了。。。我是伞兵🤡 ","link":"https://wangykonne.github.io/post/wu-ti/"},{"title":"决策树（理论）","content":" 7 days 决策树 决策树基本概念 决策树（Decision Tree）是一种基本的分类与回归方法，当决策树用于分类时称为分类树，用于回归时称为回归树。决策树是一种非常直观简单的模型，在训练阶段它从给定的训练集构造一棵树，从根节点开始选择最有价值的特征开始切分节点，并重复切分出新叶子节点直到所有叶子节点均为纯节点。决策树还有boosting和bagging两种改进方法，在后面的文章再写。 特征选择规则 上面说到，分裂节点时决策树会选择最有价值的特征进行节点的切分，那么什么叫“最有价值”呢？这里有两种衡量的方法：熵（Entropy）和基尼系数（Gini）。 ①熵：定义H(x)=−∑i=1ppilog2piH(x)=-\\sum_{i=1}^p p_ilog_2p_iH(x)=−∑i=1p​pi​log2​pi​为节点x的熵值，其中pip_ipi​表示分裂后每个类别的比例，一共p个类别满足p1+p2+...pp=1p_1+p_2+...p_p=1p1​+p2​+...pp​=1。可以看到，当pi=1p_i=1pi​=1时，节点x的熵为0，熵越高表示数据越混乱。故分裂节点的标准为：每次分裂时选择能使分裂前后熵降最大的特征作为分裂的标准，直到叶节点全为纯节点。 ②基尼系数：定义G(x)=∑i=1ppi(1−pi)=1−∑i=1ppi2G(x)=\\sum_{i=1}^p p_i(1-p_i)=1-\\sum_{i=1}^p p_i^2G(x)=∑i=1p​pi​(1−pi​)=1−∑i=1p​pi2​为节点x的熵值，同熵的定义pip_ipi​表示分裂后每个类别的比例，一共p个类别满足p1+p2+...pp=1p_1+p_2+...p_p=1p1​+p2​+...pp​=1。同样，基尼系数也是越大数据越混乱，纯节点x的基尼系数为0。故分裂准则为：每次分裂时选择能使分裂前后基尼系数下降最大的特征作为分裂的标准，直到叶节点全为纯节点。 剪枝 决策树有一个缺点：容易使树结构过于复杂，造成模型的过拟合，因此有时需要对决策树进行“剪枝”操作，去掉一部分过于复杂且实际意义不大的叶子节点来减少模型的过拟合。决策树剪枝的基本策略有预剪枝和后剪枝。 预剪枝是指在决策树生成过程中，对每个结点在划分前先进行估计，若当前结点的划分不能带来决策树泛化性能提升，则停止划分并将当前结点标记为叶结点。具体的划分限制例如：限制树的深度、限制叶子节点的个数、限制叶子节点中包含的样本数等。 后剪枝则是先从训练集生成一棵完整的决策树，然后自底向上地对非叶结点进行考察，若将该结点对应的子树替换为叶结点能带来决策树泛化性能提升，则将该子树替换为叶结点。相比于预剪枝，后剪枝更常用，因为在预剪枝中精确地估计何时停止树增长很困难。 ","link":"https://wangykonne.github.io/post/jue-ce-shu-yu-sui-ji-sen-lin-li-lun/"},{"title":"数分面试题（持续更新）","content":" 摘自各个网站的面经帖 一个网站一段时间销售额变低，应从哪几个方面去考量 首先，要定位到现象真正发生的位置，即到底是谁的销售额变低了？这里可以划分的维度有：①用户（画像，来源地区，新老，渠道等），是否是有某个特征的用户量下降了导致的销售额变低？②产品或者栏目板块，是否是某个产品或者某个特定栏目板块导致的销售额变低？③访问时段，是否是某个时段的销售额突然下降了？ 定义到发生的位置后，对问题进行拆解，具体套路是把销售额的计算量化，分析是哪个指标导致的销售额变低。例如：销售额=入站流量*下单率*客单价，入站流量=∑\\sum∑各来源流量*流量转化率，下单率=商品页面访问量*下单转化率，客单价=商品数量*商品价格。 确定到问题的源头后，对问题的原因进行分析，比如采取内外部框架：①内部：网站改版，产品更新，优化广告投放；②外部：用户偏好变化，媒体舆论环境，经济形势，竞品行为。 用户流失分析 套用上面的分析套路。首先定位到现象真正发生的位置，即到底是哪里的用户流失了。例如：①用户（画像，来源地区，新老等），可能是某个年龄段某个地区或新/老用户发生了流失；②产品，如果公司不止一个产品，要定位是哪个产品的用户发生了流失；③渠道，用户接触产品的渠道不同（如同个游戏有官服和各种渠道服），可能是某一个渠道的用户发生了流失。 指标拆解：用户流失数量=某群体用户数量*流失率。拆解看是因为到了这个阶段的用户数量多了（比如说大部分用户到了衰退期），还是这个用户群体的流失率比较高。 内外部分析原因：①内部：产品对新用户不友好，收费不合理，产品服务出现重大问题，活动质量低，缺少留存手段，用户参与度低依赖度低；②外部：市场变化，竞品行为，社会舆论环境，节假日等。 新老用户流失的区别 新用户流失：原因可能有非目标用户（刚性流失）、产品不满足需求（自然流失）、产品难以上手（受挫流失）和竞争产品影响（市场流失）。对于新用户流失，要考虑的是如何在较少的数据支撑下做流失用户识别，提前防止用户流失，并如何对有效的新用户进行挽回。 老用户流失：原因可能有到达用户生命周期衰退期（自然流失）、过度拉升arpu（每用户平均收入）导致低端用户驱逐（刚性流失）、社交蒸发难以满足前期用户需求（受挫流失）和竞争产品影响（市场流失）。老用户有较多的数据，更容易进行流失用户识别，做好防止用户流失更重要。并且，当老用户流失后，要考虑用户生命周期剩余价值，是否需要进行挽回。有关新老用户的用户周期，可以参考下图： GMV在一段时间内上升了20%，怎么分析 指标上升题都可以套上面的套路，但这种指标严重异动的情况暗示了有坑，在噼里啪啦一顿分析之前，不妨先检验一下是否是简单的计算错误。 如果指标真的没有问题，就按套路的流程走。定位异常位置：进行用户群体、产品、渠道的细分，定位GMV在哪个点上提升了；指标拆解：将指标的计算量化，如GMV=广告投放数量*广告点击率*产品浏览量*放入购物车率*交易成功率*客单价，检查哪一步有显著变化导致了GMV上升；原因分析：还是分为内外两部分，内部原因考虑网站、产品、广告投放、活动等，外部原因考虑市场、社会舆论、竞品、节假日等。 最好，这一题要注意，GMV流水包括取消的订单金额和退货/拒收的订单金额，还有一种原因是商家刷单然后退货，虽然GMV上去了，但是实际成交量并没有那么多。如果GMV上升但营收没有太大变化就可以定位这个问题。 ","link":"https://wangykonne.github.io/post/shu-fen-mian-shi-ti-chi-xu-geng-xin/"},{"title":"正则化理论 ","content":" 机器学习的矫枉过正 正则化方法 介绍正则化之前，首先要知道“过拟合”问题，即模型的参数过多导致模型过于复杂，在训练数据集上效果很好，但在预测新数据时效果很差，专业说法叫模型泛化能力差。 根据奥卡姆剃刀原则，两个模型效果一样应该选简单的那个，就是这个道理。所以有必要在机器学习过程中“惩罚”那些复杂的模型。在损失函数中引入惩罚，就是正则化方法。具体地，分为L1惩罚和L2惩罚。 L1惩罚 L1惩罚在损失函数中附加了待估参数的绝对值之和的某个倍数，即新的损失函数为： Jnew=Jold+λ∑j∣wj∣J_{new}=J_{old}+\\lambda \\sum_j\\left|w_j\\right| Jnew​=Jold​+λj∑​∣wj​∣ 其中，wjw_jwj​为待估参数，λ\\lambdaλ为L1正则化待选择的超参数，一般要训练得到。如果熟悉范数可以看到，其实惩罚项就是λ\\lambdaλ倍的待估参数θ\\thetaθ的1-范数的值。 另外，L1正则化有一个特点，就是L1正则化会减少模型中参数的个数，为什么会这样呢，如果你画出1-范数的单位区域就明白了，如下图： 显然，在这个正方形区域做最优化问题时，最优解在顶点上的概率非常高，而顶点即意味着需要一些参数取0，所以L1正则化有一定的特征筛选的功能，如果模型的特征个数很多很多，就可以用L1惩罚进行正则化。 L2惩罚 L2惩罚在损失函数中附加了待估参数的平方和的某个倍数，即新的损失函数为： Jnew=Jold+λ∑jwj2J_{new}=J_{old}+\\lambda \\sum_jw_j^2 Jnew​=Jold​+λj∑​wj2​ 其中，wjw_jwj​为待估参数，λ\\lambdaλ为L2正则化待选择的超参数，也要通过训练得到。同理，L2惩罚项就是λ\\lambdaλ倍的待估参数θ\\thetaθ的2-范数的值。 正则化参数λ\\lambdaλ 正则化是结构风险最小化的一种策略实现，能够有效降低过拟合。损失函数实际上包含了两个方面：一个是训练样本误差。一个是正则化项。其中，参数λ\\lambdaλ起到了权衡的作用。当λ\\lambdaλ比较大时，惩罚的影响很大，模型容易欠拟合；当λ\\lambdaλ比较小时，惩罚的力度比较小，模型又容易过拟合。所以，这又是一种矛盾的状态了，怎么选择合适的λ\\lambdaλ呢？（交给电脑就好了~） ","link":"https://wangykonne.github.io/post/zheng-ze-hua-li-lun/"},{"title":"逻辑回归（理论）","content":" 字节的数据挖掘岗初筛过了，估计马上就要通知面试了，赶紧复习一下以前写的机器学习的理论知识（临时抱佛脚） 逻辑回归 众所周知，逻辑回归一般用来解决二分类问题（即因变量y的取值只有0，1）。首先，要搞清楚为什么y的取值只有01时不能还用普通的线性回归呢？原因在专业课的学习中看到过：①y只有两个取值时，误差项ϵ\\epsilonϵ就不服从正态分布了，所以线性回归的基本假设不成立了；②普通线性回归预测出来的y值混乱，会出现大于1或小于0这样无法解释的情况。 实际上，逻辑回归是广义线性模型的一种，激活函数是Sigmoid函数。还有一些例如泊松回归，负二项回归等就不介绍了。 Sigmoid函数和Softmax函数 首先来了解一下逻辑回归中重要的Sigmoid函数，g(z)=11+e−zg(z)=\\frac{1}{1+e^{-z}}g(z)=1+e−z1​，其中z=θTx=θ1x1+...θnxnz=\\theta^Tx=\\theta_1x_1+...\\theta_nx_nz=θTx=θ1​x1​+...θn​xn​，所以，在逻辑回归中预测函数为，hθ(x)=g(z)=11+e−θTxh_{\\theta}(x)=g(z)=\\frac{1}{1+e^{-\\theta^Tx}}hθ​(x)=g(z)=1+e−θTx1​，模型的待估参数为θ=[θ1,θ1...θn]\\theta=[\\theta_1,\\theta_1...\\theta_n]θ=[θ1​,θ1​...θn​]。函数hθ(x)h_{\\theta}(x)hθ​(x)的值有特殊的含义，它表示结果取1的概率，即： P(y=1∣x,θ)=hθ(x),P(y=0∣x,θ)=1−hθ(x)P(y=1|x,\\theta)=h_{\\theta}(x),P(y=0|x,\\theta)=1-h_{\\theta}(x) P(y=1∣x,θ)=hθ​(x),P(y=0∣x,θ)=1−hθ​(x) 所以为什么逻辑回归要用Sigmoid函数呢？其实我也不清楚，但Sigmoid对二分类问题的优良特点或许能说明：①Sigmoid的函数值限制在0到1之间，方便理解为概率；②Sigmoid函数让各个类别的概率值加起来为1（在softmax函数中体现地更清晰） 在多元逻辑回归中，激活函数变为Softmax函数，又称为归一化指数函数，设y有n个取值0到n-1，自变量有m个特征，类别i对应的待估参数为θi=[θi1,θi2...θim]\\theta_i=[\\theta_{i1},\\theta_{i2}...\\theta_{im}]θi​=[θi1​,θi2​...θim​]，预测函数为： P(y=i∣x,θ0...θn−1)=eθiTx∑j=0n−1eθjTxP(y=i|x,\\theta_0...\\theta_{n-1})=\\frac{e^{\\theta_i^Tx}}{\\sum_{j=0}^{n-1}e^{\\theta_j^Tx}} P(y=i∣x,θ0​...θn−1​)=∑j=0n−1​eθjT​xeθiT​x​ 与Sigmoid函数相同，Softmax函数值也限制在0到1之间，且各个类别的概率值加起来为1。 损失函数 逻辑回归的损失函数算是比较好推导的，下面来复习一遍。 首先，上面提到了函数hθ(x)h_{\\theta}(x)hθ​(x)的值有特殊的含义，它表示结果取1的概率，那么预测值y其实可以看做服从一个二项分布，其取0和1的概率上面已经给出，y的概率函数为: P(y∣x;θ)=(hθ(x))y(1−hθ(x))1−yP(y|x;\\theta)=(h_{\\theta}(x))^y(1-h_{\\theta}(x))^{1-y} P(y∣x;θ)=(hθ​(x))y(1−hθ​(x))1−y 所以对于m个样本x，模型的似然函数为： L(θ)=∏i=1mP(yi∣xi;θ)=∏i=1m(hθ(xi))yi(1−hθ(xi))1−yiL(\\theta)=\\prod_{i=1}^mP(y_i|x_i;\\theta)=\\prod_{i=1}^m(h_{\\theta}(x_i))^{y_i}(1-h_{\\theta}(x_i))^{1-y_i} L(θ)=i=1∏m​P(yi​∣xi​;θ)=i=1∏m​(hθ​(xi​))yi​(1−hθ​(xi​))1−yi​ 对数似然函数为： l(θ)=logL(θ)=∑i=1m(yiloghθ(xi)+(1−yi)log(1−hθ(xi)))l(\\theta)=logL(\\theta)=\\sum_{i=1}^m(y_ilogh_{\\theta}(x_i)+(1-y_i)log(1-h_{\\theta}(x_i))) l(θ)=logL(θ)=i=1∑m​(yi​loghθ​(xi​)+(1−yi​)log(1−hθ​(xi​))) 由极大似然法应该让l(θ)l(\\theta)l(θ)最大，所以损失函数可以取为对数似然函数的相反数，为了方便后面求梯度计算，一般再除以m，得到逻辑回归的损失函数为： J(θ)=−1m∑i=1m(yiloghθ(xi)+(1−yi)log(1−hθ(xi)))J(\\theta)=-\\frac{1}{m}\\sum_{i=1}^m(y_ilogh_{\\theta}(x_i)+(1-y_i)log(1-h_{\\theta}(x_i))) J(θ)=−m1​i=1∑m​(yi​loghθ​(xi​)+(1−yi​)log(1−hθ​(xi​))) 那么怎么求解这个损失函数的最优θ\\thetaθ呢？可以利用梯度下降法进行求解，具体θ\\thetaθ的更新过程为（这里假设有m个样本，一个样本有n个特征）： θj=θj−αδδθjJ(θ)\\theta_j=\\theta_j-\\alpha \\frac{\\delta}{\\delta_{\\theta_j}}J(\\theta) θj​=θj​−αδθj​​δ​J(θ) 上式的具体化简过程就不写了，比较长看了也基本记不住，直接给最后的结果： δδθjJ(θ)=1m∑i=1m(hθ(xi)−yi)xij\\frac{\\delta}{\\delta_{\\theta_j}}J(\\theta)=\\frac{1}{m}\\sum_{i=1}^m(h_{\\theta}(x_i)-y_i)x_i^j δθj​​δ​J(θ)=m1​i=1∑m​(hθ​(xi​)−yi​)xij​ 其中xijx_i^jxij​表示第i样本的第j个特征的值。 优缺点 逻辑回归是机器学习里最简单好理解的模型，其优点就是便于理解，可以直观看到各个特征的权重且速度快。缺点也很明显，模型比较简单甚至简陋，对数据和场景的适应能力有局限性，不如树类算法适应性那么强。 还剩下啥？ 其实逻辑回归还有正则化的问题，但我准备开一篇新日志写，所以这部分会写在另外。 ","link":"https://wangykonne.github.io/post/luo-ji-hui-gui-li-lun/"},{"title":"专业词汇汇总（持续更新）","content":" 为了防止出现面试听到一个名词直接懵逼的情况出现，有必要学习一些业务上常见的名词 GMV 是什么？ GMV，全称Gross Merchandise Volume，指网站或平台的成交金额，具体地，指的是拍下订单的总金额，包含付款和未付款两部分（甚至拍下付款后退货的订单也会计入GMV中）。 怎么算？ GMV（成交总额）是用来衡量平台竞争力（市场占有率）的指标。通常电商平台的GMV=销售额+取消订单金额+拒收订单金额+退货订单金额，即GMV为已付款订单和未付款订单之和。 和营收有什么区别？ 在大致的计算公式中就可以看出，GMV是大于实际营收。 有什么用处？ ①GMV可以用来研究顾客的购买意愿，即顾客下单之后发生取消拒收退货的比率。当一个特定的产品的实际营收/GMV的值偏小时，说明顾客对产品的喜好度不高，即使通过各种营销手段让顾客购买了产品，但还是有较多客户对产品不是很钟意。 ②虽然GMV的计算是有水分的（例如淘宝里的刷单），但GMV还是能一定程度上体现一个平台、公司的竞争力。 留存率 是什么？ 留存率顾名思义，就是用户留下来继续使用的比率。以时间跨度的不同，又可以分为：次留率（用户在某天登录后第二天再次登录的比率），3日留存率（用户在某天登录后，三天后再次登录的比率）...以此类推 怎么算？ 在任意门面试被问到过，用SQL计算次留率，当时写的很麻烦，其实只要以登陆时间表（有用户UID和登录日期）在参考日期left join自己，选择两次登录日期之差=1的用户的数量/参考日期登录的总用户数量就行了。 和流失率的关系 一般来说留存率是用新增用户计算的，而流失率是用老用户计算的；即新用户看留存率，老用户看流失率。 有什么用处？ 留存率反映的实际上是一种转化率，即由初期的不稳定的用户转化为活跃用户、稳定用户、忠诚用户的过程，随着这个留存率统计过程的不断延展，就能看到不同时期的用户的变化情况。通过计算新用户不同时间维度的留存率和老用户不同时间维度的流失率，可以从宏观上把握用户的生命周期长度，从而对产品进行分析改进等。 埋点 是什么？ 所谓“埋点”，是数据采集领域（尤其是用户行为数据采集领域）的术语，指的是针对特定用户行为或事件进行捕获、处理和发送的相关技术及其实施过程。比如用户某个icon点击次数、观看某个视频的时长等等。埋点的技术实质，是先监听软件应用运行过程中的事件，当需要关注的事件发生时进行判断和捕获。例如：期望采集某个app的某个广告的有效曝光数，有效曝光的判别条件是停留时长超过1秒且有效加载出广告内容。这就是一种“埋点”。 怎么埋？ 埋点技术有三种：代码埋点，可视化埋点，无埋点。 ①代码埋点：在网页/app中加上一些代码，当用户触发相应行为时，进行数据上报，也就是代码埋点。这样的代码，在网站上叫监测代码，在app中叫SDK（Software Development Kit）。这种埋点的优点是能详细设置埋点的条件，得到的数据很精确；缺点是时间人力成本大（因为需要开发人员也参与）。 ②可视化埋点：利用可视化交互手段，数据产品/数据分析师可以通过可视化界面（管理后台连接设备）配置事件，可以理解为有一个可视化的埋点客户端，在上面点一点就行。优点是只需要了解业务就能自行埋点（无需开发人员）；缺点是仅支持客户端行为，小公司没有这类客户端就不能进行可视化埋点。 ③无埋点：例如开发人员在某个app上集成采集SDK后，SDK便直接开始捕捉和监测用户在应用里的所有行为，并全部上报，不需要开发人员添加额外代码。数据分析师通过管理后台的圈选功能来选出自己关注的用户行为，并给出事件命名，之后就可以结合时间属性、用户属性、事件进行分析了。所以无埋点不是真的不埋点，而是抓取所有数据然后按需取出。优点是一劳永逸，一次取出的所有数据可以供多次埋点使用（在时限内）；缺点是一般采集的数据远远大于埋点所需要的数据。 ","link":"https://wangykonne.github.io/post/zhuan-ye-ci-hui-hui-zong-chi-xu-geng-xin/"},{"title":"ABtest","content":" 后知后觉的我在看到很多大厂实习开始招人后才恍然大悟，嗯该开始准备准备了 今天准备的是ABtest相关的知识，作为商业数分类的岗位，这算是一个比较基础的知识，但我对它的理解仅仅是假设检验Orz。 ABtest原理 首先介绍一下ABtest背后的数学原理和逻辑吧。这里有必要复习一下统计学的两个重要定理了（防止面试被问到专业知识还答不上来很丢脸）。 ①以最简单的伯努利大数定律为例：设μn\\mu_nμn​为n次独立的实验中事件A发生的次数，且事件A在一次实验中发生的概率为p，则对任意小的正数ϵ\\epsilonϵ，下式成立： limn→∞P(∣μnn−p∣&lt;ϵ)=1lim_{n\\rightarrow \\infty}P(\\left|\\frac{\\mu_n}{n}-p\\right|&lt;\\epsilon)=1 limn→∞​P(∣∣∣​nμn​​−p∣∣∣​&lt;ϵ)=1 还有其他的大数定律，这里不多介绍，总之，这些大数定律描述的都是一件事：随着样本容量n的增加，样本平均数将接近于总体平均数，从而为统计推断中依据样本平均数估计总体平均数提供了理论依据。一句话概括就是频率的稳定性。 ②中心极限定理（独立同分布下）：设随机变量X1X_1X1​，X2X_2X2​...XnX_nXn​独立同分布，且具有有限的期望E(Xi)=μE(X_i)=\\muE(Xi​)=μ，D(Xi)=σ2D(X_i)=\\sigma^2D(Xi​)=σ2，则对于任意的x，分布函数Fn(x)F_n(x)Fn​(x)满足： limn→∞Fn(x)=limn→∞P{∑i=1nXi−nμσn≤x}=Φ(x)lim_{n\\rightarrow \\infty}F_n(x)=lim_{n\\rightarrow \\infty}P\\lbrace \\frac{\\sum_{i=1}^nX_i-n\\mu}{\\sigma \\sqrt{n}}\\leq x\\rbrace=\\Phi(x) limn→∞​Fn​(x)=limn→∞​P{σn​∑i=1n​Xi​−nμ​≤x}=Φ(x) 中心极限定理告诉我们在实际工作中，只要n足够大，便可以把独立同分布的随机变量之和当作正态变量处理，这是假设检验的基石。 如何做一次好的ABtest？ ①确定对照组和实验组，最好是做单变量的实验，一次只改变一个变量。 ②分流时尽量排除混杂因素，一般情况下采用随机分流即可。 ③检查流量是否达到最小样本量要求，达不到要求则没法进行后续的分析，实验结果不可信。注：虽然样本量越大越好，但过大的样本量不一定能获得，且如果实验会导致收入降低那样本量越大给公司的损失就越大。 ④确定本次实验的对比指标，就是如果方案之间存在差别需要通过什么来衡量？ ⑤准确收集用户行为数据，这就要求埋点必须正确。 ⑥分析指标的显著性，如果指标不显著则表示实验无效。 ⑦确定引起显著性的根本原因，排除混杂因素导致的实验结果的显著性。 ⑧最终给出实验结论：有效 or 无效。 可以看到，虽然内核只是假设检验，但ABtest对业务sense的要求还是比较高的，以后要多多实践才行。 可能会问到的问题 ①什么是p值？（p值是可以拒绝原假设的最小显著性水平。所以p值越小说明实验越显著，一般以p&lt;0.05为有统计学差异，p&lt;0.01为有显著统计学差异） ②z检验和t检验的差别？（大样本用z，小样本用t，一般认为&lt;30的样本量为小样本） ③一些别的统计学知识（考验老本的时候到了） ","link":"https://wangykonne.github.io/post/abtest/"},{"title":"返校随笔","content":" 现在是2月18号下午14点46分，我坐在回上海的高铁上。一如往常，“返校综合症”让我又depressed 起来，既不想看番也不想打游戏也不想看剧。那么能做点啥打发时间呢？于是我打开了手机的备忘录。 小王来自江西一个靠近省会的小县城，初中毕业后他便离开了这里去了别的地方上高中，随后是上大学上研究生。故乡这个词在很早的时候就在他的心中有了实感。 结束了疲惫的一个学期，小王提着行李箱又回到了这里。每年返乡，小王都能感到许多故地都不在了，它们或店铺转让或改建成了大楼，剥夺了小王故地重游的权利。还好，这里还有家人和挚友，毕竟小王返乡的目的无非就是见见想见的人。 和爸妈吃饭后的客厅闲聊是小王回家后经常参与的环节，虽然八年里爸妈的中心思想基本都没变——好好学习。可今年，上了研究生的小王感觉到了爸妈思想的变化，爸妈开始希望小王能找个稳定的工作，他们不希望小王太辛苦，也不在乎薪资和私企的差异，具体的工作名叫“公务员”。小王是个迟钝的人，现在也没有认清自己想要的生活，似乎996和965对他没有差别，于是他只能用“还没想好”搪塞。爸妈暗示小王可以找女朋友了，可小王母胎单身，人生中唯一一次被表白还是在初中，也不懂怎么和女生聊天，只好苦笑着沉默。只有小王自己知道，自己在这方面反而在倒退，成长只是把小王从阳光开朗的男孩变成了一个阴沉自闭的闷葫芦。其实小王已经做好了单一辈子的plan B，只是不想在团聚的节日说这个。爸妈开始盘算小王买房的事，可小王看着那起飞的房价，只觉得晕眩和烦躁。工作结婚买房，长大后的事情真是无趣，小王这样想到。 小王在家乡有四个发小——小李、小刘、小付、小陈。小李小陈和小王在同个城市，他们一个在研究所读直博一个已经是社畜。小刘和小付去年则在家乡备考二战。回家后和发小们的日常是每年的保留环节。小王经常怀疑自己是不是有双重人格（误），仿佛回家和老朋友玩耍的时候小王就摘下了自闭面具，成为了另一个人，而在别的地方小王又会变成自闭的呆瓜。或许是社交圈子太小了吧，应该多去交朋友，小王经常这样想，但小王却很难再做到让人认识真实的自己，面具背后往往又是另一个面具。如何真诚地与人交往，这是小王尚需学习的一个课题。 两周的假期很快就结束了，小王这两周算是真正快乐了一小会，但想到开学后的种种事，他又陷入焦虑和不安中。离开的这天是个大晴天，小王的印象中每次离乡都有蒙蒙细雨，今天倒是没有，这么好的天气，小王想去森林公园转转，但老爸提醒他该走了，老爸送小王到了车站。小王候车时打开了日历，今天恰是雨水节气，春天的气息逐渐接近了，小王在心中许下了牛年的愿望。 “希望家人身体健康” “希望小刘小付今年能成功上岸” “希望小王能做出改变，抑或是和解” ","link":"https://wangykonne.github.io/post/fan-xiao-sui-bi/"},{"title":"TF-IDF小白入门","content":" 小年快乐，耶~ TF-IDF理论小白入门 何为TF-IDF？ TF-IDF，全称为term frequency-inverse document frequency，是一种用来评估文本中某些字词的重要性的加权统计方法，可以应用在搜索引擎上。TF-IDF算法的核心思想是：字词的重要性会随着它在某一文档中的出现次数正比增加，但会随着它在整个语料库中的出现次数反比减少。例如：如果整个语料库为所有有关英雄联盟的文档，在某一篇电竞春晚的文章中，“Rookie”和“的”这两个词的出现频率都很高（可以理解为词频相近），但显然“的”在整个语料库中的出现次数比“Rookie”高，所以“的”对这篇电竞春晚的文章的重要性显然不如“Rookie”。 TF-IDF的原理 顾名思义，TF-IDF分为两种要素的计算，词频TF与逆向文本频率IDF。 ①TF。词频TF的计算限制在某一份特定的文档中，与整个语料库的大小无关，TF的计算公式也很简单，指的就是特定词tit_iti​在特定文档中出现的频率，如下： tfi,j=ni,j∑knk,jtf_{i,j}=\\frac{n_{i,j}}{\\sum_k n_{k,j}} tfi,j​=∑k​nk,j​ni,j​​ 上面式子中，ni,jn_{i,j}ni,j​表示词tit_iti​在文档djd_jdj​中的出现次数，分母则表示文档djd_jdj​中所有词语的个数。 ②IDF。逆向文本频率度量的是一个词语在语料库中的普遍重要程度，特定词tit_iti​在整个语料库中出现的IDF由总文件数除以包含词语tit_iti​的文件数的商再取自然底数的对数得到，如下： idfi=log⁡∣D∣∣{j:ti∈dj}∣idf_i=\\log\\frac{\\left|D\\right|}{\\left|\\lbrace j:t_i\\in d_j\\rbrace\\right|} idfi​=log∣{j:ti​∈dj​}∣∣D∣​ 其中，∣D∣\\left|D\\right|∣D∣表示语料库中的文件总数，∣{j:ti∈dj}∣\\left|\\lbrace j:t_i\\in d_j\\rbrace\\right|∣{j:ti​∈dj​}∣表示包含词语tit_iti​的文件数目（即ni,j≠0n_{i,j}\\neq 0ni,j​​=0的文件数目），为了防止分母为0，有时也采用1+∣{j:ti∈dj}∣1+\\left|\\lbrace j:t_i\\in d_j\\rbrace\\right|1+∣{j:ti​∈dj​}∣作为分母。 最后，词语tit_iti​在文本djd_jdj​中的TF-IDF得分为：tfidfi,j=tfi,j∗idfitfidf_{i,j}=tf_{i,j}*idf_itfidfi,j​=tfi,j​∗idfi​ 从公式可以看出，要产生高权重值的TF-IDF依赖于两方面：①在某一个特定文本djd_jdj​中，词语tit_iti​是高频词；②同时，该词语tit_iti​在整个文本中有低文件频率。因此，TF-IDF算法倾向于过滤掉常见的无实意词语（如“的”）而保留重要的词语。 便于理解的example 在某个一共有1000词的网页中“原子能”、“的”和“应用”分别出现了2次、35次和5次，那么它们的词频TF就分别是0.002、0.035和0.005。假定中文网页数是D=10亿，词“的”在所有的网页中都出现，那么它的IDF=log(10亿/10亿)=log(1)=0IDF=log(10亿/10亿)=log(1)=0IDF=log(10亿/10亿)=log(1)=0。假如专用词“原子能”在两百万个网页中出现，则它的IDF=log(10亿/200万)=log(500)=6.2IDF=log(10亿/200万)=log(500)=6.2IDF=log(10亿/200万)=log(500)=6.2。又假定通用词“应用”出现在五亿个网页中，它的权重IDF=log(10亿/5亿)=log(2)=0.7IDF=log(10亿/5亿)=log(2)=0.7IDF=log(10亿/5亿)=log(2)=0.7。 则最终“原子能”、“的”和“应用”的TF-IDF值分别为：0.0126、0和0.0035。该网页和“原子能的应用”的相关度可以用词语的TF-IDF之和表示，即0.0161。 可以看到，TF-IDF算法在计算相关度上有一定合理性，上面的例子中“的”明显是一个对相关性没有帮助的词，计算后贡献的TF-IDF为0（或者接近0）。 注意事项 ①如果对中文文本库进行TF-IDF计算，首先需要进行中文分词操作，这点不同于英文。 ②TF-IDF算法默认词与词之间是相互独立的进行计算，而实际中相邻词之间会有一定关系，而TF-IDF无法反映这些信息。 ③按照TF-IDF的计算，往往一些生僻词的IDF(反文档频率)会比较高，因此这些生僻词常会被误认为是文档关键词，而实际上这些生僻词有些仅仅是噪声。 ④IDF的计算在文本集已经分类完毕的情况下精度会下降，因为在一系列同类别的语料中，往往重要的单词也会有比较高的出现频率，而IDF的计算值却会比较低，会引起误差。 总结 总体来说TF-IDF是一种比较简单直观又快速的算法，有一些不足，但应用还是很广的，比如搜索引擎、提取关键词、文本相似性和文本摘要...放假在家无心学习，具体实战操作以后有空再更。 ","link":"https://wangykonne.github.io/post/tf-idf-xiao-bai-ru-men/"},{"title":"Word2vec实战练习","content":" Word2vec小白入门练习 Word2vec实战练习 前置准备 进行中文文本的Word2vec词向量构建，首先需要进行分词。所以在这次练习中，需要预先安装好python中的分词库jieba和word2vec的库gensim。直接使用pip install的方法安装快捷又省心。 实战过程 #加载库 import jieba import jieba.analyse from string import punctuation from gensim.models import word2vec #创建好分词前和分词后txt文件的路径 source_txt = 'C:/Users/wangyuankai/Desktop/report.txt' target_txt = 'C:/Users/wangyuankai/Desktop/result.txt' source_file = open(source_txt, 'r', encoding = 'utf-8') target_file = open(target_txt, 'w', encoding = 'utf-8') #定义要删除的标点等字符，punctuation里自带有一些半角标点，因此只需再补一些全角标点即可 add_punc='，。、【 】 “”：；（）《》‘’{}？！⑦()、%^&gt;℃：.”“^-——=&amp;#@￥' all_punc=punctuation+add_punc #对文本进行分词操作并去除标点符号和无实意的停用词 line = source_file.readline() stopwords = str(&quot;的和要以并为是&quot;) while line: #第一次分词得到既有中文分词又有标点符号，以空格为间隔 line_seg = &quot; &quot;.join(jieba.cut(line)) #移除标点等需要删除的符号 testline=line_seg.split(' ') te2=[] for i in testline: te2.append(i) if i in all_punc or i in stopwords: te2.remove(i) #返回的te2是个list，转换为string后少了空格，因此需要再次分词 #第二次在仅有汉字的基础上再次进行分词 line_seg2 = &quot; &quot;.join(jieba.cut(''.join(te2))) target_file.writelines(line_seg2) line = source_file.readline() source_file.close() target_file.close() #word2vec建模并储存 sentences = word2vec.Text8Corpus('C:/Users/wangyuankai/Desktop/result.txt') model = word2vec.Word2Vec(sentences, size=1000) model.save('C:/Users/wangyuankai/Desktop/test.model') #应用举例（获取最相似的n个词语，计算相似度） print(&quot;与脱贫最相似的五个词语为&quot;) print(model.wv.most_similar(&quot;脱贫&quot;,topn=5)) print(&quot;脱贫与民生的相似度为&quot;) print(model.wv.similarity('脱贫','民生')) 上面代码运行的结果为： &quot;与脱贫最相似的五个词语为&quot; &quot;[('发展', 0.34930261969566345), ('疫情', 0.29745471477508545), ('保障', 0.29070693254470825), ('人员', 0.2822575271129608), ('推动', 0.2802283763885498)]&quot; &quot;脱贫与民生的相似度为&quot; &quot;0.27995038&quot; 个人总结 上面的实战过程中，有必要说明一下的就是word2vec.Word2vec()函数了。Word2vec函数的基本形式为：Word2vec(sentences,size=100,alpha=0.025,window=5, min_count=5, max_vocab_size=None, sample=0.001,seed=1, workers=3, sg=0, hs=0, negative=5, cbow_mean=1,iter=5,null_word=0, sorted_vocab=1, batch_words=10000)) 参数含义：①sentences就是待训练的语料，小文本可以用list输入，大文本也可以用我上面的Text8Corpus方法输入；②size表示词向量的维度，越大训练越慢但效果越好；③alpha表示学习速率；④window表示最多考虑特定词前后各window个词语进行建模；⑤min_count表示用来建模的词语的最小词频，词频小于min_count的词语会被舍弃；⑥max_vocab_size设置词向量构建期间的RAM限制。如果所有独立单词个数超过这个，则就消除掉其中最不频繁的一个;⑦sample为高频词汇的随机降采样的配置阈值；⑧workers设置训练的并行核数；⑨seed为随机数种子；⑩sg=0使用CBOW算法，sg=1使用skip-gram算法；①①hs=0采用negative sampling技巧，hs=1使用hierarchica softmax技巧；①②negative设置使用negative sampling技巧时具体用几个sample；①③cbow_mean如果为0，则采用上下文词向量的和，如果为1则采用其均值；①④iter迭代次数；①⑤sorted_vocab=1时会在分配word index的时候会先对单词基于频率降序排序；①⑥batch_words每一批的传递给训练线程的单词的数量。 虽然参数看起来很多，但其实影响比较大的就几个，首先size的设置是最重要的，一般要根据文本的大小进行设置，如果太小会丢失很多信息，太大又会让词语间的相似度变得很低降低应用价值；其次min_count也比较重要，如果确定每个词语都是需要的，那应该设置min_count=1防止词语被舍弃；其余的参数可以就使用默认值进行训练。 最后分享一个工作中踩过的坑，如果你是把分词后的词语一个个先存在list中，比如words=[&quot;词语1&quot;,&quot;词语2&quot;,&quot;词语3&quot;]，那在训练过程中，一定要写成sentences=[words]而不能直接写sentences=words。因为Word2vec会默认sentences输入了一段文本，会对list中的词语再进行一次分词，那会把words中的词语拆成单个的字进行建模，最后使用模型的时候会出现“word XX not in vocabulary”这样的错误。（当然，如果你min_count设置的高也会可能导致低频词不在vocabulary中） 以上就是一个简单的实战练习，Word2vec用的最多的不是相似度或者近义词，而是用训练好的模型将词语向量化，将文字转化为数值向量从而方便进行其他机器学习算法的建模（用model[word]实现）。一句话概括，Word2vec只是一种特征处理的工具。 ","link":"https://wangykonne.github.io/post/word2vec-shi-zhan-lian-xi/"},{"title":"Word2vec小白入门","content":" 一些才疏学浅的见解 最近实习在做的是一个类似NLP的模型，然而此前在学校并没有了解过NLP的相关概念，所以工作中也是现学现卖。前几天终于把初版的模型跑出来了，因此先把最近学习到的东西写下来防止以后忘了。 词的向量化方法 在介绍Word2vec之前，有必要了解一下两种词向量化的方法：①One-hot；②Distributed。（可能不止这两种，但目前我只看了这两种方法） One-hot表示法 One-hot表示法之前就有接触过，简单的说，这种方法经常用于离散的类别化的特征转换，例如：公司旁边的奶茶店有CoCo、七分甜、一点点，那就可以把奶茶店这个特征进行One-hot编码，用[1,0,0]表示CoCo，[0,1,0]表示七分甜，[0,0,1]表示一点点。虽然这样做会将特征升维，但这样可以将离散的类别化特征变得可处理。（毕竟单纯用0,1,2表示类别是不太合理的，因为这样就隐含了大小信息） 同样，在词向量的表示上，也有One-hot编码方法。假设一个词库中有N个词语，那one-hot就会为每一个词语分配一个索引，使之转化为一个N维向量。举个例子，假设词库中现在有：Today、is、Monday、Tuesday、Sunny五个词，那Today is Monday这句话经过One-hot表示法转化为词向量就变为[1,1,1,0,0]，非常易懂。 但这种方法其实存在不足。首先，一般词库是非常大的，而一句话中所能包含的词语有限，所以这种方法生成的词向量往往是稀疏的，在词库很大很大的情况下容易造成维数灾难；其次，一句话中的词语之间往往也是有关系的，而one-hot表示法不能体现这一点，它仅仅是记录每个词语是否出现或出现多少次，即Today is Monday和Is today monday?是一样的表示方法，但显然两者的含义是不一样的。 Distributed表示法 Distributed表示法是一种通过神经网络将句子中的词语训练为限定维数K的向量的方法，且这种方法得到的向量是稠密的，不仅仅能记录词语，还能表示上下文词语的关系。唯一需要考虑的就是如何选取恰当的K，一般要参考词库的大小。 Word2vec简介 什么是Word2vec？ 用一句通俗的话概括，Word2vec就是采用Distributed表示法，将原本是one-hot形式的稀疏词向量表示为一个指定维数n的稠密词向量的方法。词语是NLP的最小维度的单位，如何将符号性质的词语转化为数值形式就衍生出了词嵌入方法（word embedding），即将词语嵌入到指定维数的数学空间中，本质上，Word2vec就是一种词嵌入方法。Word2vec要做的就是分析一句话中的某个词语与前后m个词语的关系，或者是词语x与词语y放在一起是否符合自然语言的法则。在实际应用中，我们并不关心Word2vec模型的结果怎么样，而是更关注训练出模型的参数并用来转化一些现实的句子。 CBOW和Skip-Gram CBOW（Continuous Bag-of-Word Model）又称为连续词袋模型，整体是一个三层神经网络，该模型的特点是通过输入某个词前后的一段语料或者词库，输出对该词的预测结果。如下图所示： 对某个特定的词语，显然CBOW预测词语为w时必然也是后验概率P(w∣Context(w))P(w|Context(w))P(w∣Context(w))最大的时候，所以对于一段语料或者词库中所有的词语，可以得到，CBOW的学习目标就是最大化对数似然函数L(w)L(w)L(w)： L(w)=∑w∈ClogP(w∣Context(w))L(w)=\\sum_{w\\in C}logP(w|Context(w)) L(w)=w∈C∑​logP(w∣Context(w)) 加上一个负号即得到损失函数，为最优化问题的目标函数： Loss(w)=−∑w∈ClogP(w∣Context(w))Loss(w)=-\\sum_{w\\in C}logP(w|Context(w)) Loss(w)=−w∈C∑​logP(w∣Context(w)) 下面这张图描绘了了CBOW的训练过程： 简单解释一下就是：①首先，在Input layer中，我们考虑&quot;某个词&quot;前后共C个词语的one-hot表示的向量，假设维数为1*V（V表示词库或语料的总维数），那么对于这C个1*V的向量，通过神经网络训练一个词语的权值矩阵WV∗NW_{V*N}WV∗N​，这里N就是我们想要的词向量的维数；②用这C个1*V的向量分别与权值矩阵WV∗NW_{V*N}WV∗N​相乘得到C个1*N的向量，在hidden layer中取平均得到一个1*N的向量；③最后用hidden layer中的这个1*N的向量再与权值矩阵的转置WTW^{T}WT相乘，变回一个1*V的向量。 此时得到的这个1*V的向量的每个分量表示的就是对应词语在&quot;某个词&quot;这个位置上的概率值，概率最大的词语就是Word2vec模型预测出的中间词。 Skip-Gram则是恰好与CBOW的思路相反，它的输入是词库或语料中的一个词语，输出则是这个词语前后共C个词语，因此Skip-Gram的训练过程类似CBOW，只是过程相反，就不多说了，具体类似下图： Some Tricks 不管是CBOW还是Skip-Gram，我们需要通过神经网络训练的都是权值矩阵WV∗NW_{V*N}WV∗N​，共V*N个待训练参数，然而在实际应用中这是个规模非常大的矩阵，首先word2vec方法内置的默认N=1000即使用1000维的词向量，那么如果待训练的词库有10000个词则就有10000000个待训练参数，这将会是非常慢的，同时这么大的权重矩阵就需要更多的训练样本来防止出现过拟合现象。因此，Word2vec内置了两种优化的训练方法： ①层序softmax（hierarchical softmax）方法 用CBOW举例，在上面提到的训练过程中，从hidden layer的1*N的向量到output layer的1*V的概率向量的过程中，激活函数是softmax函数，但这样的话我们需要计算V次softmax函数的值来得到所有词语在中间位出现的概率值。而使用层序softmax方法，我们只需要计算log2Vlog_2Vlog2​V次，这相当于从多项式时间复杂度变为对数时间复杂度。具体的计算过程如下图： 类比CBOW的output层得到的全部V个词的概率，在上面这个霍夫曼树中表现为V个叶子节点；而由权重矩阵投影后的1*N词向量在树中表现为根节点n(w2,1)n(w_2,1)n(w2​,1)；而隐藏层的一些神经元则体现为树的内部节点。直观上看，此时原来神经网络中的一步softmax转化为霍夫曼树中沿不同父节点进行一次又一次的sigmoid转化，这就是hierarchical softmax的直观体现。具体细节可以理解为：首先定义向左分支为1，向右分支为0（相反也行），此时方向就可以看成一个逻辑回归，这样判别一个给定的词w就转化为沿着父节点一次次进行sigmoid函数的计算。 这种方法的好处很明显：首先降低了时间复杂度；其次如果词库或语料中有高频词汇，其在霍夫曼树中会更加靠近根节点的位置（因为出现的概率大），这样就能更快寻找到正确的词w。 ②负采样（negative sampling）方法 层序softmax方法虽然能显著降低算法的时间复杂度，但也有一些不足，即如果我们要训练的是一个很生僻的词语，则需要在霍夫曼树中往下深入很多。而负采样方法的思想能一定程度上优化这个不足，它将词库或者语料中一些出现频率非常高的词作为negative samples，而频率非常高的词一般没有什么实际意义（例如英文中的the和汉语中的&quot;的&quot;）。本质上，这种方法实际上是对训练集进行采样来减少训练集的大小。 简单地说下流程就是：①首先选择neg个negative samples出来；②对中间位的前后C个词，只使用这neg个negative samples和1个正例样本进行训练，即由原来的权值矩阵WV∗NW_{V*N}WV∗N​变为WV∗(1+neg)W_{V*(1+neg)}WV∗(1+neg)​，这就大大简化了模型待训练的参数。（插点个人的理解，这种方法不应该会丢失很多信息吗？感觉是一种非常偷懒的方法...不过也可能是我没理解透这个方法的含义吧） 最后，如何选择negative samples呢？用一种形象的表述就是：如果词库或者语料vocab的词总数为V，那么我们就将一段长度为1的线段分成V份，每份对应词汇表中的一个词。当然每个词对应的线段长度是不一样的，高频词对应的线段长，低频词对应的线段短。每个词w的线段长度由下式决定: len(w)=count(w)∑u∈vocabcount(u)len(w)=\\frac{count(w)}{\\sum_{u\\in vocab}count(u)} len(w)=∑u∈vocab​count(u)count(w)​ 在某paper上已经有大佬给出了调试好的公式，对分子分母都取了3/4次幂: len(w)=count(w)3/4∑u∈vocabcount(u)3/4len(w)=\\frac{{count(w)}^{3/4}}{{\\sum_{u\\in vocab}count(u)}^{3/4}} len(w)=∑u∈vocab​count(u)3/4count(w)3/4​ Word2vec其实不关注模型 Word2vec模型可以分为两部分：模型与模型训练得到的权值矩阵W。 正如标题所言，大部分情况下我们对Word2vec模型本身并不感兴趣，真正有用的是通过训练后模型内的权值矩阵W，得到这个权值矩阵W后，我们就可以将任意一段词语在词库中的句子或文章进行向量化了。简而言之，Word2vec只是一种工具，我们需要的只是模型的中间产物，最后的模型结果判断中间词之类的一般用不着（因为语料中我们已经知道真实词是哪一个了） 总结 以上就是我上周对Word2vec一些内容的学习。总体还是学的挺浅的，毕竟是目标导向的学习，没有深入了解算法背后的一些数学原理比如怎么最小化损失函数啊之类的，嗯以后有机会或许会补充（如果看得懂的话）。如果之后mentor没有布置任务的话，还有些TFIDF相关的内容和工作中写代码踩过的雷可以更新。 ","link":"https://wangykonne.github.io/post/word2vec-xiao-bai-ru-men/"},{"title":"破事儿氵","content":" 单纯倒垃圾，没什么好看的 社畜初体验 实习生活两周了，从一开始在群里每天哔哔“好想上班啊”到每天痛苦面具“又要上班了”。倒不是因为上班多辛苦任务多繁重之类的，相反，这两周我就只学了点NLP的基础知识写了点SQL和Python，其余时间一直在摸🐟。真正痛苦的是通勤，来回三个小时实在让人疲惫，并且早晚高峰更让痛苦放大，好在能在地铁上看看动漫（下周应该还能玩玩方舟）。 工作内容还算轻松，写写Python有时按y哥的要求写写SQL，可能不足的是没有数分方面的锻炼吧。最后，工作之后才认识到：兴趣对工作热情的影响还挺大的。没有兴趣的话平常工作的驱动力真的好低，经常写着写着就摸起🐟来了，希望暑假能去b站或者游戏公司实习，不过谁又知道是不是另一座围城呢，自己究竟喜欢怎样的工作和生活，还是要体验了才知道吧。 一些负能量 虽然学期结束了工作也挺轻松，但自己最近反而心情不太好。回想了一下，跟考试成绩陆续出来而自己又普遍考的不太好有一定关系。虽然自己知道绩点的用处不太大，但毕竟老小镇做题家了，潜意识里还是对分数异常敏感。明明这学期压根没付出努力，上课除了听课啥都干，却还是幻想能靠突击取得好成绩，现在公平的结果出来了自己又不高兴。不得不说，这样的自己真是挺让人讨厌的，就像临时抱佛脚失败的人完事后还骂骂咧咧地离开一样。 自我反思，很多时候，自己的负能量都源于自己过于期待一件事情的结果。看一本书期待它能让自己变深刻，运动期待能让自己瘦一斤又一斤，发信息期待能收到回复，考试期待能取得好成绩（不管是否有付出努力），分享一个故事说一个心情期待被关注被安慰。这些期待往往只关心最后的结果，如果运气好结果可能是自己想要的，但一旦期待落空就会让人陷入自怨自艾。所以我似乎明白了为什么小时候的自己更加快乐，因为小时候更在意的是过程。快乐地走好当下的过程，少去关注功利化的结果，也许是这个问题的最优解。 因为心情不好，周五还怼了老妈几句，明明老妈只是希望我周末能少玩游戏多看书，我却有点上火并表示坚决不看还发了一大堆气话。其实老妈一直都是这样说，我平常也不太听，但负面情绪的影响让我又伤害了真正在意自己的人。说起来自己平常在基友群里也是净倒垃圾没发点有用的东西，仿佛越亲密越好当自己的垃圾桶，甚至自己还理所应当好朋友就是如此云云。总是伤害爱自己的人可不好啊，以后一定要改掉这个坏毛病，都成年人了，有空向亲密的人懊丧发泄，不如去操场跑个几公里来的解压。 ","link":"https://wangykonne.github.io/post/po-shi-san/"},{"title":"SQL学习笔记（十五）","content":" 学习用书：SQL基础教程（Mick著） 数据库：MySQL 数据库可视化软件：SQLyog 今日不想学习，把所有的SQL笔记都搬运完了，还有一些自己写在笔记本上的内容整理完再发上来。 第八章：SQL 高级处理 8.2 GROUPING运算符 8.2.1 ROLLUP——同时得到合计和小计 ROLLUP是一种GROUPING运算符，它可以算出合计行。例如想查询各个商品种类的合计销售价格并得到一个合计行： #查询各个商品种类的合计销售价格并得到一个合计行 #DB2,Oracle,SQL Server,PostgreSQL SELECT product_type, SUM(sale_price) AS sum_price FROM product GROUP BY ROLLUP(product_type); #MySQL SELECT product_type, SUM(sale_price) AS sum_price FROM product GROUP BY product_type WITH ROLLUP; 注意MySQL中ROLLUP用法的区别，上面的代码可以得到一个合计sum_price行，但这行的其他列为NULL值。下面再来试试如何得到小计，首先将regist_date加入GROUP BY子句中： #按商品类别和注册时间分组查询商品类别、注册时间和销售价的总和 SELECT product_type, regist_date, SUM(sale_price) AS sum_price FROM product GROUP BY product_type, regist_date; 此时在使用ROLLUP函数就可以得到厨房用具SUM值的小计和办公用品SUM小计和衣服的SUM小计： #使用ROLLUP函数就可以得到厨房用具SUM值的小计和办公用品SUM小计和衣服的SUM小计 #DB2,Oracle,SQL Server,PostgreSQL SELECT product_type, regist_date, SUM(sale_price) AS sum_price FROM product GROUP BY ROLLUP(product_type, regist_date); #MySQL SELECT product_type, regist_date, SUM(sale_price) AS sum_price FROM product GROUP BY product_type,regist_date WITH ROLLUP; 8.2.2 GROUPING函数——让NULL更加容易分辨 在上面代码的结果中，衣服的分组有两列regist_date为NULL值，但这两个NULL值的原因是不一样的，第一个NULL是因为记录本身就是NULL值，但第二个NULL是因为这一行是小计行所以regist_date被设置为NULL。为此，SQL特意设置了一个GROUPING函数，对于第一个NULL会返回0，第二个NULL则会返回1，下面用GROUPING函数重复下上面的例子： #用GROUPING函数重复上面的例子 #DB2,Postgre SQL,SQL Server,Oracle SELECT GROUPING(product_type) AS product_type, GROUPING(regist_date) AS regist_date, SUM(sale_price) AS sum_price FROM product GROUP BY ROLLUP(product_type, regist_date); #MySQL SELECT GROUPING(product_type) AS product_type, GROUPING(regist_date) AS regist_date, SUM(sale_price) AS sum_price FROM product GROUP BY product_type, regist_date WITH ROLLUP; 这样就可以分辨合计小计和普通值了，（0，0）即为普通值，（0，1）即为一种商品种类的小计值，（1，1）即为所有数据的合计值。但这样也有一个问题，明显product_type和regist_date的原来信息丢失了，0和1在实际中没什么别的意义。结合前几天学过的CASE函数就可以得到一个很漂亮的合计小计表： #使用CASE函数和GROUPING函数得到最完美的合计小计表 #DB2,Postgre SQL,SQL Server,Oracle SELECT CASE WHEN GROUPING(product_type)=1 THEN '合计' ELSE product_type END AS product_type, CASE WHEN GROUPING(regist_date)=1 AND GROUPING(product_type)&lt;&gt;1 THEN '小计' WHEN GROUPING(regist_date)=1 AND GROUPING(product_type)=1 THEN 'NULL' ELSE CAST(regist_date AS VARCHAR(16)) END AS regist_date, SUM(sale_price) AS sum_price FROM product GROUP BY ROLLUP(product_type, regist_date); #MySQL SELECT CASE WHEN GROUPING(product_type)=1 THEN '合计' ELSE product_type END AS product_type, CASE WHEN GROUPING(regist_date)=1 AND GROUPING(product_type)&lt;&gt;1 THEN '小计' WHEN GROUPING(regist_date)=1 AND GROUPING(product_type)=1 THEN 'NULL' ELSE CAST(regist_date AS VARCHAR(16)) END AS regist_date, SUM(sale_price) AS sum_price FROM product GROUP BY product_type, regist_date WITH ROLLUP; 需要注意的是，CASE的返回值要是同一个类型，所以当直接输出regist_date时要用CAST函数将日期转化为字符串。 8.2.3 CUBE——用数据搭积木 下面来介绍另一个GROUPING函数，即CUBE。CUBE语法和ROLLUP语法相同，所以我们用上面的例子，将ROLLUP换为CUBE看看会得到什么结果： #使用CUBE查询 #DB2,Oracle,SQL Server,PostgreSQL SELECT product_type, regist_date, SUM(sale_price) AS sum_price FROM product GROUP BY CUBE(product_type,regist_date); #MySQL 未找到正确使用方法,可能还没实装 总之，与ROLLUP相比，GROUP BY ROLLUP(A1,A2..An)会返回n+1个汇总结果即GROUP BY(),GROUP BY(A1),GROUP BY(A1,A2)..GROUP BY(A1,A2..An)。而GROUP BY CUBE(A1,A2..An)会返回2n2^n2n个汇总结果即Cn0+Cn1+...Cnn=2nC_n^0+C_n^1+...C_n^n=2^nCn0​+Cn1​+...Cnn​=2n的全组合。所以上面代码的最终结果就是多了GROUP BY(regist_date)的记录。 8.2.4 GROUPING SETS——取得单列的汇总结果 GROUPING SETS和ROLLUP和CUBE都是一样的语法，类似地，GROUP BY GROUPING SETS(A1,A2..An)会返回恰好n个汇总结果即GROUP BY(A1)...GROUP BY(An)，所以这个函数只会取出单列汇总结果的查询数据，同样看一个应用的例子： #使用GROUPING SETS查询 #DB2,Oracle,SQL Server,PostgreSQL SELECT product_type, regist_date, SUM(sale_price) AS sum_price FROM product GROUP BY GROUPING SETS(product_type,regist_date); #MySQL 未找到正确使用方法,可能还没实装 ","link":"https://wangykonne.github.io/post/sql-xue-xi-bi-ji-shi-wu/"},{"title":"SQL学习笔记（十四）","content":" 学习用书：SQL基础教程（Mick著） 数据库：MySQL 数据库可视化软件：SQLyog 第八章：SQL 高级处理 8.1 窗口函数 8.1.1 什么是窗口函数 窗口函数也被称为OLAP函数，即Online Analytical Processing，窗口函数就是用来实现实时分析功能的函数，在SQL Server和Oracle中也被成为分析函数。 8.1.2 窗口函数的语法 窗口函数的基础语法为：&lt;窗口函数&gt; OVER (PARTITION BY &lt;列名&gt; ORDER BY &lt;列名&gt;)。能够作为窗口函数使用的函数有两种：①聚合函数；②专用的窗口函数如RANK,DENSE_RANK,ROW_NUMBER。 8.1.3 RANK函数使用方法 下面学习RANK函数的使用方法来理解一下窗口函数的语法。例如对product表的不同商品种类分别进行销售单价的升序排序： #对product表的不同商品种类分别进行销售单价的升序排序 SELECT product_name, product_type, sale_price, RANK() OVER (PARTITION BY product_type ORDER BY sale_price) AS ranking FROM product; 从例子中可以理解，PARTITION设定的是排序的对象范围，可以从字面意思理解为用来分割不同组；ORDER BY和前面学的ORDER BY用法完全一致。从窗口函数的用法可以看出，它兼具了GROUP BY的分组功能和ORDER BY的分类功能，但不具备GROUP BY的汇总功能。PARTITION BY相当于把表划分为一个个窗口，进行各自的操作。 8.1.4 不指定PARTITION BY 在不指定PARTITION BY时，使用窗口函数会把整个表当成一个窗口。例如上面的例子中，如果删去PARTITION BY就会得到和直接使用ORDER BY一样的结果： #对product表销售单价的升序排序 SELECT product_name, product_type, sale_price, RANK() OVER (ORDER BY sale_price) AS ranking FROM product; 8.1.5 专用窗口函数的种类 下面来总结一下具有代表性的专用窗口函数： RANK函数：计算排序时，如果存在相同位次的记录，则会跳过之后的位次。例如有3条记录并列第一时：1，1，1，4。 DENSE_RANK函数：如果存在相同位次的记录，也不会跳过之后的位次。例如有3条记录并列第一时：1，1，1，2。 ROW_NUMBER函数：赋予唯一的连续位次。例如有3条记录并列第一时：1，2，3，4。 最后用一个例子使用这三种函数来看看最后的结果： #比较RANK函数、DENSE_RANK函数、ROW_NUMBER函数的结果 SELECT product_name, product_type, sale_price, RANK() OVER (ORDER BY sale_price) AS ranking, DENSE_RANK() OVER (ORDER BY sale_price) AS dense_ranking, ROW_NUMBER() OVER (ORDER BY sale_price) AS row_num FROM product; 8.1.6 窗口函数的适用范围 窗口函数只能写在SELECT子句之中，一句话，直接死记硬背就完事。 8.1.7 聚合函数作为窗口函数使用 聚合函数也可以作为窗口函数使用，但功能会有一点不同。例如以SUM函数为例子： #将SUM函数作为窗口函数 SELECT product_id, product_name, sale_price, SUM(sale_price) OVER (ORDER BY product_id) AS cur_sum FROM product; 使用SUM窗口函数时，括号内有参数，这点和RANK家族的不一样。上面代码的结果是根据product_id升序进行累加求和，即cur_sum第一行是id为0001的sale_price，第二行是id为0001和0002的sale_price之和...AVG在用在窗口函数时也是这种累计的功能： #将AVG函数作为窗口函数 SELECT product_id, product_name, sale_price, AVG(sale_price) OVER (ORDER BY product_id) AS cur_avg FROM product; 8.1.8 计算移动平均 窗口函数还包括更加详细的汇总范围的备选功能，即框架。例如想计算排序后一个值和前面两行的平均值，显然这是一个移动平均值，上面的方法用不了： #计算每个列值和前两行的平均值 SELECT product_id, product_name, sale_price, AVG(sale_price) OVER (ORDER BY product_id ROWS 2 PRECEDING) AS moving_avg FROM product; ROWS关键字用来指定行，PRECEDING表示向前，FOLLOWING表示向后；所以ROWS 2 PRECEDING表示自己和前两行数据。再来看一个同时使用PRECEDING和FOLLOWING的例子： #计算每个列值和前后各一行的平均值 SELECT product_id, product_name, sale_price, AVG(sale_price) OVER (ORDER BY product_id ROWS BETWEEN 1 PRECEDING AND 1 FOLLOWING) AS moving_avg FROM product; 同时使用前后时要使用BETWEEN AND语句连接，其他的MIN,MAX,SUM,COUNT函数的窗口函数用法也类似，就不举例了。 ","link":"https://wangykonne.github.io/post/sql-xue-xi-bi-ji-shi-si/"},{"title":"SQL学习笔记（十三）","content":" 学习用书：SQL基础教程（Mick著） 数据库：MySQL 数据库可视化软件：SQLyog 第七章：集合运算 7.2 联结（以列为单位对表进行联结） 7.2.1 什么是联结 上一节学了三种集合运算UNION,INTERSECT,EXCEPT；这三种运算都是以表的行为单位的，即对表的行进行操作。而联结则是一种以列为单位的运算，它可以将多个表按列并在一起，有点像R语言中的cbind函数连接矩阵。SQL中的联结分为两种：内联结和外联结。 7.2.2 内联结 之前在学习子查询的时候我们创建了一个表shopproduct，它有四列，其中有一列和product名相同，即两个表的所有列分为两种：①两张表都有的列——product_id,②只存在其中一张表的列。联结运算，其实就是以①中的列为桥梁，将②中满足条件的列汇集到同一张新表中。如下：以product_id联结product和shopproduct表： #以product_id联结product和shopproduct表 #SQL Server,MySQL,PostgreSQL,DB2 SELECT SP.shop_id, SP.shop_name, SP.product_id, P.product_name, P.sale_price FROM shopproduct AS SP INNER JOIN product AS P ON SP.product_id = P.product_id; #Oracle SELECT SP.shop_id, SP.shop_name, SP.product_id, P.product_name, P.sale_price FROM shopproduct SP INNER JOIN product P ON SP.product_id = P.product_id; 关于内联结有三点需要注意：①FROM子句中使用两个或多个表，这是之前学习没碰到过的，用INNER JOIN把多个表内联结起来；②ON后面跟的是联结的条件，即联结键，能起到和WHERE一样的作用，需要指定多个键时可以用AND或OR。在内联结时ON子句是不可少的，且ON要书写在FROM和WHERE之间。所以到目前为止，子句的书写顺序为——SELECT FROM ON WHERE GROUPBY HAVING ORDERBY；③SELECT子句在查询列时前面要加上表的别名，否则容易引发混乱。最后来看一个内联结和WHERE结合使用的例子，在上面的问题中如果只想查询店ID为000A的门店的信息时： #以product_id联结product和shopproduct表且只想查询店ID为000A的门店的信息 #SQL Server,MySQL,PostgreSQL,DB2 SELECT SP.shop_id, SP.shop_name, SP.product_id, P.product_name, P.sale_price FROM shopproduct AS SP INNER JOIN product AS P ON SP.product_id = P.product_id WHERE SP.shop_id = '000A'; #Oracle SELECT SP.shop_id, SP.shop_name, SP.product_id, P.product_name, P.sale_price FROM shopproduct SP INNER JOIN product P ON SP.product_id = P.product_id WHERE SP.shop_id = '000A'; 当然，这种内联结有点像子查询，在SELECT执行之后这张新表就会消失，如果想继续使用这张表，要将它保存为视图。 7.2.3 外联结 ——OUTER JOIN 外联结OUTER JOIN的使用方法和内联结完全一致，只是结果不一样，下面我们用外联结重复上面的例子看看结果有什么不一样的地方： #以product_id联结product和shopproduct表 #SQL Server,MySQL,PostgreSQL,DB2 SELECT SP.shop_id, SP.shop_name, SP.product_id, P.product_name, P.sale_price FROM shopproduct AS SP RIGHT OUTER JOIN product AS P ON SP.product_id = P.product_id; #Oracle SELECT SP.shop_id, SP.shop_name, SP.product_id, P.product_name, P.sale_price FROM shopproduct SP RIGHT OUTER JOIN product P ON SP.product_id = P.product_id; 外联结的要点：①选取出了单张表的全部信息，与内联结的结果相比，显然结果的行数不一样，外联结多了两行，而多出来的两个记录在shopproduct表中不存在只在product表中存在。所以外联结只要数据存在某一个表中就能在最后的结果中显示出来，那些未知列的信息统一设为NULL；②外联结还有一点就是要设置主表，即最后的结果会包含主表的全部信息，可以用LEFT或RIGHT来指定主表，上面的例子用的是RIGHT，表示右边的是主表，也可以用LEFT代替，两者得到的结果完全一样： #以product_id联结product和shopproduct表 #SQL Server,MySQL,PostgreSQL,DB2 SELECT SP.shop_id, SP.shop_name, SP.product_id, P.product_name, P.sale_price FROM product AS P LEFT OUTER JOIN shopproduct AS SP ON SP.product_id = P.product_id; #Oracle SELECT SP.shop_id, SP.shop_name, SP.product_id, P.product_name, P.sale_price FROM product P LEFT OUTER JOIN shopproduct SP ON SP.product_id = P.product_id; 7.2.4 三张以上表的联结 首先创建一个库存商品表，包括仓库编号、商品编号和库存数量： #创建表InventroyProduct CREATE TABLE InventoryProduct ( inventory_id CHAR(4) NOT NULL, product_id CHAR(4) NOT NULL, inventory_quantity INTEGER NOT NULL, PRIMARY KEY (inventory_id, product_id)); #插入数据 START TRANSACTION; INSERT INTO InventoryProduct (inventory_id, product_id, inventory_quantity) VALUES ('S001', '0001', 0); INSERT INTO InventoryProduct (inventory_id, product_id, inventory_quantity)VALUES ('S001', '0002', 120); INSERT INTO InventoryProduct (inventory_id, product_id, inventory_quantity) VALUES ('S001', '0003', 200); INSERT INTO InventoryProduct (inventory_id, product_id, inventory_quantity) VALUES ('S001', '0004', 3); INSERT INTO InventoryProduct (inventory_id, product_id, inventory_quantity) VALUES ('S001', '0005', 0); INSERT INTO InventoryProduct (inventory_id, product_id, inventory_quantity) VALUES ('S001', '0006', 99); INSERT INTO InventoryProduct (inventory_id, product_id, inventory_quantity) VALUES ('S001', '0007', 999); INSERT INTO InventoryProduct (inventory_id, product_id, inventory_quantity) VALUES ('S001', '0008', 200); INSERT INTO InventoryProduct (inventory_id, product_id, inventory_quantity)VALUES ('S002', '0001', 10); INSERT INTO InventoryProduct (inventory_id, product_id, inventory_quantity) VALUES ('S002', '0002', 25); INSERT INTO InventoryProduct (inventory_id, product_id, inventory_quantity) VALUES ('S002', '0003', 34); INSERT INTO InventoryProduct (inventory_id, product_id, inventory_quantity) VALUES ('S002', '0004', 19); INSERT INTO InventoryProduct (inventory_id, product_id, inventory_quantity) VALUES ('S002', '0005', 99); INSERT INTO InventoryProduct (inventory_id, product_id, inventory_quantity) VALUES ('S002', '0006', 0); INSERT INTO InventoryProduct (inventory_id, product_id, inventory_quantity) VALUES ('S002', '0007', 0); INSERT INTO InventoryProduct (inventory_id, product_id, inventory_quantity) VALUES ('S002', '0008', 18); COMMIT; 下面取出InventoryProduct表中的库存数量，和shopproduct,product进行内联结，以product_id为联结键： #内连接三张表，并查询P001号仓库的商品信息 #SQL Server,MySQL,PostgreSQL,DB2 SELECT SP.shop_id, SP.shop_name, SP.product_id, P.product_name, P.sale_price, IP.inventory_quantity FROM shopproduct AS SP INNER JOIN product AS P ON SP.product_id = P.product_id INNER JOIN InventoryProduct AS IP ON SP.product_id = IP.product_id WHERE IP.inventory_id = 'P001'; #Oracle SELECT SP.shop_id, SP.shop_name, SP.product_id, P.product_name, P.sale_price, IP.inventory_quantity FROM shopproduct SP INNER JOIN product P ON SP.product_id = P.product_id INNER JOIN InventoryProduct IP ON SP.product_id = IP.product_id WHERE IP.inventory_id = 'P001'; 内联结可以对多张表进行联结，只需要INNER JOIN——ON——INNER JOIN——ON这样一致重复下去就可以。外联结也是一样的。 7.2.5 交叉联结——CROSS JOIN 交叉联结用的比较少，可以理解为不用ON的内联结，因为没有联结键，所以最后的数据量会之间相乘，例如product中有8条记录而shopproduct中有13条记录，故交叉联结后会有13*8=104条记录： #交叉联结两张表 #SQL Server,MySQL,PostgreSQL,DB2 SELECT SP.shop_id, SP.shop_name, SP.product_id, P.product_name, P.sale_price FROM shopproduct AS SP CROSS JOIN product AS P; #Oracle SELECT SP.shop_id, SP.shop_name, SP.product_id, P.product_name, P.sale_price FROM shopproduct SP CROSS JOIN product P; 交叉联结很像集合的乘法，即集合乘后的数据量等于之前数据量的乘积。但这种联结一般很少用到，因为没有什么有用的信息且会耗费太多的运算时间和资源。 ","link":"https://wangykonne.github.io/post/sql-xue-xi-bi-ji-shi-san/"},{"title":"滤镜","content":" 今天下地铁买个了外包装很好看的面包当晚餐，然而吃下去的味道却让人一言难尽。所以自己为什么会买它呢？恐怕一定程度上就是自己单纯被自己脑补催眠哎呀这么精致肯定味道也不会差到哪里去啦。简而言之，潜意识里，我已经带上了滤镜看这个面包。 作为钢铁直男的我，生活中很少用到滤镜。却不知，在过去很多年的生活中，自己在看待很多事物上都或多或少带有一点美化的滤镜心理。倒不是说自己讨厌这种滤镜下的认知，毕竟也不是第一天知道自己的这种倾向，只是凡事期望越大失望也越大，一旦滤镜破碎往往受伤的也是自己。现在想想，我目前为数不多的人生经历中发生过许多这种事，所以我到底是个理想主义者还是现实主义者？唔我现在也不太确定了。 可能是小时候每年暑假都会来上海找我哥玩的缘故，从小我就对上海这座城市充满了好感，毕竟小城镇的孩子突然间来到大城市，就仿佛知道了牡丹花比小野花要艳丽得多一样。并且家里人也希望我以后能去上海读大学，可惜最后没有考上去了厦大，这可能是加重了滤镜效应的原因吧，所以即便放弃留在厦大的保研资格我也选择了考交大来上海。现在在上海的几个月过去了，感受却和从前大不相同，虽然可能有成长的原因在里面，但还是能感到心中的落差，从前一直认为是国内最好的城市，现在只能在发达程度上苟同。脱离了自己脑补出来的各种滤镜下的印象，才发现，哦原来我喜欢的不是上海，而是自己脑中强加给这座城市的一些“我以为”下的上海。所以你并不是真的喜欢这座城市，而是喜欢自己虚构出来的另一座城市罢了。同样，去过几次成都旅游后，我对成都的好感也直线上升，甚至经常想着毕业干脆去成都生活好了。嗯，这一次一定要深思熟虑，最好能有空提前去成都“破滤镜”感受一下哈哈。 不止是事物，看人方面也存在滤镜效应。长大了就会发现，往往自己喜欢的人并没有自己想象的那么完美，滤镜仿佛给大脑带上了墨镜，失去了理性的判断就经常容易脑袋一热误以为她就是Ms.Right。wyk，要记住曾经翻车的血泪史啊！ 人不是机器，思维总会有主观性，所以滤镜效应是不可避免的。但还是希望自己能多一点理性少一点“我以为”。不管以后是看人还是看事，都不要刻板印象或者脑补美化，而要更objective一点！ ","link":"https://wangykonne.github.io/post/lu-jing/"},{"title":"SQL学习笔记（十二）","content":" 学习用书：SQL基础教程（Mick著） 数据库：MySQL 数据库可视化软件：SQLyog 第七章：集合运算 7.1 表的加减法 7.1.1 什么是集合运算 迄今为止，我们已经学了对单个表的所有增删改查及各种函数的用法。本节来学习集合运算，即表之间的运算，如表的加减法。 7.1.2 表的加法——UNION 在前面插入数据的学习中，我们创建了一个表productcopy和product表一样，后来又往里面添加了一个数据。即productcopy的前八条数据和product一样，第九条数据是独有的。下面我们来用UNION连接这两个表： #用UNION连接productcopy,product SELECT product_name, product_type FROM product UNION SELECT product_name, product_type FROM productcopy; 上面的代码结果会返回9行数据而不是17行，简而言之，UNION其实就相当于集合的并集，它会返回在两表的全部商品并去重。 7.1.3 集合运算的注意事项 ①作为运算对象的记录中的列的数量和类型必须一致。如果两个表的列的数量不同或者同一位置的列的数据类型不一样都会发生错误。 ②可以使用任何SELECT语句，但ORDER BY 子句只能在最后使用一次，下面给一个示例，查询两个表中厨房用具的ID号和商品名并连接，最后按ID升序排列： #查询两个表中厨房用具的ID号和商品名并连接，最后按ID升序排列 SELECT product_id, product_name FROM product WHERE product_type = '厨房用具' UNION SELECT product_id, product_name FROM productcopy WHERE product_type = '厨房用具' ORDER BY product_id ASC; 7.1.4 包含重复行的集合运算——ALL 前面介绍过，UNION相当于集合的并集运算，得到的结果不会有重复行。但也可以得到包含重复行的结果，只需要在UNION后面加关键字ALL就可以了： #用UNION连接productcopy,product,包含重复行 SELECT product_name, product_type FROM product UNION ALL SELECT product_name, product_type FROM productcopy; 7.1.5 选取表中的公共部分——INTERSECT 下面来学习集合的交集运算——INTERSECT，其语法和UNION完全一致： #查询两个表公共部分的ID号和商品名，并按ID号升序排列 #Oracle,SQL Server,DB2,PostgreSQL SELECT product_id, product_name FROM product INTERSECT SELECT product_id, product_name FROM productcopy ORDER BY product_id ASC; 注意，INTERSECT在MySQL中暂时不能使用。UNION的所有注意事项和ALL关键字的用法都和INTERSECT完全一致，就不多说了。 7.1.6 记录的减法——EXCEPT 最后来学习集合的差集运算——EXCEPT，其语法也和UNION相同。例如查询在productcopy而不在product表中的商品的ID和名称，按ID升序排列： #查询在productcopy而不在product表中的商品的ID和名称，按ID升序排列： #SQL Server,DB2,PostgreSQL SELECT product_id, product_name FROM productcopy EXCEPT SELECT product_id, product_name FROM product ORDER BY product_id ASC; #Oracle SELECT product_id, product_name FROM productcopy MINUS SELECT product_id, product_name FROM product ORDER BY product_id ASC; 最后要说明一点，UNION和INTERSECT执行都不论表的前后次序，即A UNION B和B UNION A是一致的。但差集运算与前后顺序是有关的，要思考好是A EXCEPT B还是B EXCEPT A。 ","link":"https://wangykonne.github.io/post/sql-xue-xi-bi-ji-shi-er/"},{"title":"SQL学习笔记（十一）","content":" 学习用书：SQL基础教程（Mick著） 数据库：MySQL 数据库可视化软件：SQLyog 实习第一天，身心俱疲。 第六章：函数、谓词和CASE表达式 6.3 CASE表达式 6.3.1 什么是CASE表达式 SQL中的CASE表达式类似C/Python中的IF语句，用来设置条件分支。（如果是MySQL应该用IF多于CASE） 6.3.2 CASE表达式的语法 CASE语句的基本语法为： CASE WHEN &lt;求值表达式&gt; THEN &lt;表达式&gt; WHEN &lt;求值表达式&gt; THEN &lt;表达式&gt; WHEN &lt;求值表达式&gt; THEN &lt;表达式&gt; .... ELSE &lt;表达式&gt; END 每一个WHEN都会判断求值表达式返回的值是TRUE还是FALSE，如果为TRUE则会输出后面THEN的表达式且CASE语句到此结束。如果所有WHEN都返回的是FALSE，则会返回ELSE的表达式。 6.3.3 CASE表达式的使用方法 下面来看一个例子，用CASE表达式将ABC字符加入到商品种类中： #用CASE表达式将ABC字符加入到商品种类中 SELECT product_name, CASE WHEN product_type = '衣服' THEN CONCAT('A:',product_type) WHEN product_type = '办公用品' THEN CONCAT('B:',product_type) WHEN product_type = '厨房用品' THEN CONCAT('C:',product_type) ELSE NULL END AS abc_product_type FROM product; 上面代码连接字符串用的是CONCAT，其他的RDBMS的连接函数见前面的笔记。最后ELSE语句如果没有表达式可以省略不写，此时会默认为ELSE NULL。END语句是不能省略的。 最后，今天学的其实是搜索CASE，还有一种简单CASE，但功能被搜索CASE完全替代，如果用简单CASE做上面的例子： #用简单CASE表达式将ABC字符加入到商品种类中 SELECT product_name, CASE product_type WHEN '衣服' THEN CONCAT('A:',product_type) WHEN '办公用品' THEN CONCAT('B:',product_type) WHEN '厨房用品' THEN CONCAT('C:',product_type) ELSE NULL END AS abc_product_type FROM product; 看上去简化了代码，但如果WHEN表达式的列不相同时就不管用了，所以只用搜索CASE就好了。而且不同RDBMS中还有一些特定的CASE语句，如Oracle的DECODE，MySQL的IF语句，但CASE是通用的基础语句而且使用范围比特定的要广，所以就不学特定的CASE语句了，以后用到再补。 ","link":"https://wangykonne.github.io/post/sql-xue-xi-bi-ji-shi-yi/"},{"title":"SQL学习笔记（十）","content":" 学习用书：SQL基础教程（Mick著） 数据库：MySQL 数据库可视化软件：SQLyog 最近几个老同学来找我玩~有点玩疯了哈哈，所以今天象征性搬运一次笔记（逃） 第六章：函数、谓词、CASE表达式 6.1 谓词 6.1.1 什么是谓词 简单来说，谓词就是返回值为布尔变量的函数，其实之前用过的=,&lt;,&gt;,&lt;=,&gt;=,&lt;&gt;等比较运算符其实都是谓词。本节将会介绍以下谓词：LIKE,BETWEEN,IS NULL,IS NOT NULL,IN,EXISTS。 6.1.2 LIKE谓词——字符串的部分一致查询 =是查询字符串是否完全一致的谓词，而LIKE则是查询字符串是否部分一致的谓词。为了方便演示，先创建一个学习用表samplelike： #创建表samplelike CREATE TABLE samplelike (strcol VARCHAR(6) NOT NULL, PRIMARY KEY (strcol)); #插入数据 START TRANSACTION; INSERT INTO samplelike VALUES ('abcddd','dddabc','abdddc', 'abcdd','ddabc','abddc'); COMMIT; 此时表中数据有三个包含'ddd'，但它们的'ddd'部分包含在不同的位置，如果想得到查询结果为'dddabc','abdddc','abcddd'的字符串，则就要使用LIKE谓词和%符号了，如下： #LIKE前方一致查询 SELECT * FROM samplelike WHERE strcol LIKE 'ddd%'; #LIKE中间一致查询 SELECT * FROM samplelike WHERE strcol LIKE '%ddd%'; #LIKE后方一致查询 SELECT * FROM samplelike WHERE strcol LIKE '%ddd'; 其中的'%'符号表示的是任意长度的任意字符串，且可以为空，所以%ddd%的查询结果会同时有'dddabc','abdddc','abcddd'三个。既然有任意长度的任意字符串，那也会有定长的任意字符串，就是'_'符号了，它表示字节为1的任意字符串。例如想查询形如abc??的字符串： #查询形如abc??的字符串 SELECT * FROM samplelike WHERE strcol LIKE 'abc__'; 上面的查询固定了长度为五，且前三个字符为abc，后两个字符任意。搭配使用_和%可以达到需要模糊查询的目标。 6.1.3 BETWEEN谓词——范围查询 BETWEEN谓词的意思比较简单，就是字面上的'之间'的意思。例如想查询product表中销售单价在100到1000之间的商品时： #查询product表中销售单价在100到1000之间的商品时 SELECT product_name, sale_price FROM product WHERE sale_price BETWEEN 100 AND 1000; BETWEEN a AND b 的结果就是a&lt;= &lt;=b，所以BETWEEN AND语句会包含临界值，如果不想包含临界值还是用基础的&lt;和&gt;号吧 6.1.4 IS NULL、IS NOT NULL——判断是否为NULL IS NULL和IS NOT NULL是一对判断是否为NULL值的谓词，相当于NULL值中的等号=和不等号&lt;&gt;。例如查询进货价格为NULL值的商品，查询进货价格不为NULL的商品： #查询进货价格为NULL值的商品 SELECT product_name, purchase_price FROM product WHERE purchase_price IS NULL; #查询进货价格不为NULL的商品 SELECT product_name, purchase_price FROM product WHERE purchase_price IS NOT NULL; 6.1.5 IN谓词——OR的简便用法 前面我们学过OR的用法，即表示或者，而IN其实就是一种OR的简便用法。那如果想找出进货单价为320，500，5000的商品时，就要用两个OR来执行，而用IN则会简便很多： #用OR找出进货单价为320，500，5000的商品 SELECT product_name, purchase_price FROM product WHERE purchase_price = 320 OR purchase_price = 500 OR purchase_price = 5000; #用IN找出进货单价为320，500，5000的商品 SELECT product_name, purchase_price FROM product WHERE purchase_price IN (320,500,5000); 上面两端代码的查询结果是一样的。既然有IN，也会有NOT IN。例如希望选出进货单价不为320，500，5000的商品： #不用NOT IN选出进货单价不为320，500，5000的商品 SELECT product_name, purchase_price FROM product WHERE purchase_price &lt;&gt; 320 AND purchase_price &lt;&gt; 500 AND purchase_price &lt;&gt; 5000; #用NOT IN选出进货单价不为320，500，5000的商品 SELECT product_name, purchase_price FROM product WHERE purchase_price NOT IN (320,500,5000); 可以看到，在并列查询条件很多的时候，用IN会方便很多。 6.1.6 使用子查询作为IN谓词的参数 IN谓词可以使用子查询作为其参数，为了展现例子，先创建一个表shopproduct记录哪些商店销售哪些商品： #创建表shopproduct CREATE TABLE ShopProduct (shop_id CHAR(4) NOT NULL, shop_name VARCHAR(200) NOT NULL, product_id CHAR(4) NOT NULL, quantity INTEGER NOT NULL, PRIMARY KEY (shop_id, product_id)); #插入数据 START TRANSACTION; INSERT INTO ShopProduct (shop_id, shop_name, product_id, quantity) VALUES ('000A','东京','0001',30); INSERT INTO ShopProduct (shop_id, shop_name, product_id, quantity) VALUES ('000A','东京','0002',50); INSERT INTO ShopProduct (shop_id, shop_name, product_id, quantity) VALUES ('000A','东京','0003',15); INSERT INTO ShopProduct (shop_id, shop_name, product_id, quantity) VALUES ('000B','名古屋','0002',30); INSERT INTO ShopProduct (shop_id, shop_name, product_id, quantity) VALUES ('000B','名古屋','0003',120); INSERT INTO ShopProduct (shop_id, shop_name, product_id, quantity) VALUES ('000B','名古屋','0004',20); INSERT INTO ShopProduct (shop_id, shop_name, product_id, quantity) VALUES ('000B','名古屋','0006',10); INSERT INTO ShopProduct (shop_id, shop_name, product_id, quantity) VALUES ('000B','名古屋','0007',40); INSERT INTO ShopProduct (shop_id, shop_name, product_id, quantity) VALUES ('000C','大阪','0003',20); INSERT INTO ShopProduct (shop_id, shop_name, product_id, quantity) VALUES ('000C','大阪','0004',50); INSERT INTO ShopProduct (shop_id, shop_name, product_id, quantity) VALUES ('000C','大阪','0006',90); INSERT INTO ShopProduct (shop_id, shop_name, product_id, quantity) VALUES ('000C','大阪','0007',70); INSERT INTO ShopProduct (shop_id, shop_name, product_id, quantity) VALUES ('000D','福冈','0001',100); COMMIT; 上面创建表的过程中因为待插入的数据的任一列都不能满足主键的限制，所以选择了两列作为主键。下面来演示子查询和IN结合使用的例子，例如想查询出在大阪店（000C）在售商品的销售单价，首先我们要从shopproduct表中选择大阪店的在售商品ID，然后在product表中选择这些ID对应的商品的销售单价，具体如下： #用子查询查询出在大阪店（000C）在售商品的销售单价 SELECT product_name, sale_price FROM product WHERE product_id IN (SELECT product_id FROM shopproduct WHERE shop_id = '000C'); NOT IN也可以使用子查询，和IN一样就不给例子了。最后，子查询是一种易于维护的代码，因为它可以随着表中数据变化自动变化结果。所以以后要多多练习使用子查询 6.1.7 EXISTS谓词 EXISTS是一种使用方法特殊且有点难理解的谓词，大多数情况可以被IN替代，但我们还是学一下。EXISTS表示&quot;判断是否存在满足某种条件的记录&quot;，如果存在就返回TRUE，不存在就返回FALSE。例如，用EXISTS写上节那个子查询的例子： #用EXISTS和子查询查询出在大阪店（000C）在售商品的销售单价 SELECT product_name, sale_price FROM product AS P WHERE EXISTS (SELECT * FROM shopproduct AS SP WHERE SP.shop_id = '000C' AND SP.product_id = P.product_id); 明显使用EXISTS使代码更加晦涩难懂了。而且注意到EXIST的左侧没有任何列参数，这是EXISTS的特殊之处，即EXISTS只能在右侧书写一个参数，这个参数通常都是一个子查询，且一般是关联子查询。同时，子查询中SELECT * 也与IN例子中的写法不同，因为EXISTS只关心记录是否存在，对返回哪些列没有限制，即使写成下面这样也得到一样的结果： #子查询中的SELECT啥都行 SELECT product_name, sale_price FROM product AS P WHERE EXISTS (SELECT 1 FROM shopproduct AS SP WHERE SP.shop_id = '000C' AND SP.product_id = P.product_id); 同样，也存在NOT EXISTS，逻辑就是多了个非，没啥别的不同。最后，NOT EXISTS也一般是用关联子查询作为参数。 今天学完了五个谓词，还剩最后一节CASE表达式。 ","link":"https://wangykonne.github.io/post/sql-xue-xi-ri-ji-shi/"},{"title":"关于即将结束的2020这档子事","content":" 大概算是个年终总结？（废话连篇长文预警） 回首向来萧瑟处 疫情下的年初 真是糟糕的一年啊，大概人们在回顾这一年时都会这样想吧。确实，如此魔幻的2020真是增长了我的人生阅历。年初的时候新冠疫情爆发，每天的新增病例上升让人触目惊心，还好祖国给力控制的及时。嗯今年前四个多月都是在家里度过，这么长的寒假真是人生第一次。我过上了梦想的家里蹲生活hh，然而过了一个月就受不了了，不得不说和爸妈生活习惯还是挺难协调的（至少对我来说），尤其是在几点起床这个问题上！对于冬天一般每天9点后才起的我，年初每天被7点半叫醒吃早饭实在是太痛苦了呜呜呜😵 可能年初唯一的好消息就是初试出分那一天吧hh，当时高兴地多元网课一个字都没听进去，大脑一直空白quq。当天就立下了好好准备复试的flag，然而...在知道初试第三后，瞬间flag就倒了...每天过上了经典肥宅生活——上午起床肝毕业论文，下午晚上玩游戏看动漫Orz，果然最后复试差点翻车，分数低的一还好初试救了我QAQ😭 到三四月份时候可以出门了，晚上就和发小出去散步（吃夜宵），一般是走半小时就“啊好累啊去二中旁边看看有什么好吃的呗”。你可真行啊wyk，就这几个月胖了五六斤！后来我俩都意识到这样吃下去真得要胖成了，才稍微克制了一些...（好在现在又减回去了😁） 再见鹭岛 五月份返校咯~回到熟悉的厦门，坐上学校的校车，见到了久违的淑铌姐和室友和同学们。回到学校的瞬间就意识到了毕业在即这个事实，以前觉得遥不可及的毕业季逐渐有了实感...最让我难过的就是最后见韬的一面定格在了2019年，希望他快点好起来吧！ 论文答辩，拍毕业照，和室友走遍校园每一个角落，只想把这一切深深印在记忆中。六月份厦园的凤凰花和《凤凰花开的路口》真是绝配啊，学生会做的毕业短片bgm用的就是这个，当时第一次看到真的热泪盈眶。最后的这段时间和另外两个室友高强度约饭约玩，试图用欢声笑语忘记即将到来的分别，这可能是今年我最快乐的时光吧。 “我最爱的朋友们，祝你们一切都好，一直都好”坐上公交，看到窗外逐渐模糊的厦大，顺带告别自己在这四年的时光，眼泪彻底决堤在公交上嚎啕大哭（当然只是一直抹眼泪没有哭出声）。嗯现在回想起来真是...有点哈次卡西呢Orz 无奖竞猜：上图哪个是我？ 你好交大 终于，九月份和cbc，lz上海汇合！缘分真奇妙啊，从小一起长大的发小，最后又重新聚到了一起，一个在中科院一个同济毕业我在交大，嗯大伙都有光明的前途（确信）。开学到现在，平静又忙碌的生活，嗯似乎没有特别值得记录的事呢，除了周末经常出去玩hh，不过有所收获就够啦！貌似这个学期还算充实，选课拉满，课余时间学了点实用的工具，也找到了实习，似乎...就差脱单了哈哈哈哈哈呜呜呜（笑着笑着就哭了起来...） 也无风雨也无晴 平淡？知足！（摸鱼！） 要说2020年自己感觉自己最大的变化嘛，大概就是逐渐&quot;佛系&quot;了起来，尤其是在今年火热的&quot;内卷&quot;讨论环境中。当然，&quot;佛系&quot;也不意味着躺平，更多的是认清自己、接纳自己、和不完美和解，这也是一种成长的过程嘛！毕竟努力是为了让自己获得更多的快乐嘛，竞争内卷什么的不可避免，那就试着放平自己的心态，一味上头在热血中迷失忘记了自己真正要的是什么样的生活就得不偿失了。 来年的目标？嗯我觉得现在的状态就很不错啦，希望2021能继续保持，多学点实用的技能，争取秋招能拿到一个心仪的offer！ 葡萄成熟时 嗯2020就要过去了，至此我完成了母胎单身的第22个年头（好耶！），再坚持8年就能成为大魔法师了呢（误）。还记得大学后每年跨年都是和室友不然就是搁床上睡觉，然后信誓旦旦地表示来年一定要脱单，再然后就是经典复刻循环往复...那么，自己为什么会一直单身呢？这个问题我还真的很认真地考虑过，首先可能就是性格太太太太怂了吧，从小到大貌似总共暗恋过3个女生，最后都是不了了之，甚至有一个曾经关系很好但自己还是没能鼓起勇气表白（唉）；其次自己也是个死宅，社交圈子小又懒得去参加各种活动，不过我这种容易社恐的人估计去了也只会感觉尬想溜... 想想校园生活也没剩多少了，自己可能要永远和纯粹的校园恋爱说byebye了，或多或少还是会有些后悔吧，尤其最近看狗粮番和剧的时候更加感到对甜甜恋爱的渴望...&quot;那爱情的绮丽，总是在孤单里&quot;。不过也没什么嘛，爱情也不是生活的必需品，再不济以后去相亲好了（自我安慰中QAQ...） &quot;今晚月色真美啊&quot;，&quot;风也很温柔呢&quot;（好甜啊，多来点Orz） 2020年的最后一个愿望 最后一个愿望是：回归分析考试顺利！（这个人不复习搁着摸鱼结果还许愿考试能过，一定是笨蛋吧...嘻嘻） ","link":"https://wangykonne.github.io/post/da-gai-shi-ge-nian-zhong-zong-jie/"},{"title":"SQL学习笔记（九）","content":" 学习用书：SQL基础教程（Mick著） 数据库：MySQL 数据库可视化软件：SQLyog 第六章：函数、谓词、CASE表达式 6.1 各种各样的函数 6.1.1 函数的种类 这一章开始学习SQL中各种各样的函数。SQL的函数大致可以分为以下几种： 算术函数（用来进行数值计算的函数） 字符串函数（用来进行字符串操作的函数） 日期函数（用来进行日期操作的函数） 转换函数（用来转换数据类型和值的函数） 聚合函数（用来进行数据聚合的函数） 在第三章已经学习过COUNT,SUM,AVG,MIN和MAX这些聚合函数了，接下来来学习一些具有代表性的函数，并不需要一次记住，只需要知道有这种函数，在实际应用中查找即可。 6.1.2 算术函数 算术函数是最基本的函数，其实第二章用到的+-*/四则运算都是算术函数。为了介绍别的算术函数，先创建一个实例用表samplematch： #创建学习用表samplematch CREATE TABLE samplematch (m NUMERIC(10,3), n INTEGER, p INTEGER); #插入数据 START TRANSACTION; INSERT INTO samplematch VALUES (500,0,NULL), (-180,0,NULL), (NULL,NULL,NULL), (NULL,7,3), (NULL,5,2), (NULL,4,NULL), (8,NULL,3), (2.27,1,NULL), (5.555,2,NULL), (NULL,1,NULL), (8.76,NULL,NULL); COMMIT; 上面用到了一种新的数据结构：NUMERIC(a,b)。NUMERIC(a,b)表示数据的最大全体位数为a,小数位数定为b，如NUMERIC(10,3)保存3.14即为3.140。 ①ABS绝对值函数 这个函数没啥好解释的，直接上例子： #查询表中m列的数据的绝对值 SELECT m, ABS(m) AS abs_col FROM samplematch; 之前说过，几乎所有的运算、函数对NULL都不起作用，所以NULL值不会发生变化。 ②MOD求余函数 这个函数也没啥好说的，MOD(7,3)=1，自行体会含义。 #计算n列对p列求余数 #除SQL Server外 SELECT n, p, MOD(n,p) AS mod_col FROM samplematch; #SQL Server SELECT n, p, n%p AS mod_col FROM samplematch; 需要记住的是SQL Server不支持MOD函数，它用%代替取余运算。 ③ROUND四舍五入函数 这个函数依旧没啥好说的，ROUND(m,n)表示对m保留n位小数。 #对m列数据保留n列的位数 SELECT m, n, ROUND(m,n) FROM samplematch; 但注意m列定义的时候规定了小数位固定3位，所以ROUND(m,n)也只能取四舍五入，不能把小数位数改变。 6.1.3 字符串函数 为了学习字符串函数，我们也来创建一个实例表： #创建学习用表samplestr CREATE TABLE samplestr (str1 VARCHAR(40), str2 VARCHAR(40), str3 VARCHAR(40)); #插入数据 START TRANSACTION; INSERT INTO samplestr VALUES ('opx', 'rt',NULL),('abc','def',NULL),('山田','太郎','是我'),('aaa',NULL,NULL), (NULL,'xyz',NULL),('@!#$%',NULL,NULL),('ABC',NULL,NULL),('aBC',NULL,NULL), ('abc太郎','abc','ABC'),('abcdefabc','abc','ABC'),('micmic','i','I'); COMMIT; ①||拼接函数 SQL可以用||来连接多个字符串。例如连接str1和str2字符串： #连接str1,str2字符串 #Oracle，DB2，Postgre SQL SELECT str1, str2, str1||str2 AS str_concat FROM samplestr; #SQL Server SELECT str1, str2, str1+str2 AS str_concat FROM samplestr; #SQL Server,MySQL SELECT str1, str2, CONCAT(str1,str2) AS str_concat FROM samplestr; 可以看到拼接函数在不同的RDBMS中的用法不同，||只在Oracle,DB2,Postgre SQL中能用，MySQL使用CONCAT函数，SQL Server使用+或者CONCAT函数。 ②LENGTH字符串长度函数 这个函数没啥好说的，半角英文和符号为一个字节，汉字为两个字节。 #计算str1字符串的长度 #Oracle,DB2,Postgre SQL,MySQL SELECT str1, LENGTH(str1) FROM samplestr; #SQL Server SELECT str1, LEN(str1) FROM samplestr; 需要注意，SQL Server使用LEN()来计算字符串长度，MySQL中还有一个CHAR_LENGTH()函数也是同样的功能。 ③LOWER函数和UPPER函数 这两个函数很简单，即将所有字符转换为小写或者大写，对英文外的字符不起作用。 #将str1列字符串全部转化为小写 SELECT str1, LOWER(str1) FROM samplestr; #将str1列字符串全部转化为大写 SELECT str1, UPPER(str1) FROM samplestr; ④REPLACE函数字符串的替换 REPLACE(对象字符串,替换前的字符串,替换后的字符串)。例如把str1中出现的str2字符串替换为str3字符串： #把str1中出现的str2字符串替换为str3字符串 SELECT str1,str2,str3,REPLACE(str1,str2,str3) FROM samplestr; ⑤SUBSTRING字符串截取函数 SUBSTRING函数可以将字符串中的一部分子字符串截取出来。例如截取字符串str1中第3、4位的字符： #截取字符串str1中第3、4位的字符 #Postgre SQL, MySQL SELECT str1, SUBSTRING(str1 FROM 3 FOR 2) FROM samplestr; #SQL Server SELECT str1, SUBSTRING(str1,3,2) FROM samplestr; #Oracle,DB2 SELECT str1, SUBSTR(str1,3,2) FROM samplestr; SUBSTRING函数在不同的RDBMS中有一些细节上的不同，但结构基本一样，即字符串、截取的初始位置、截取的字符数。 6.1.4 日期函数 ①CURRENT_DATE函数获取当前日期 CURRENT_DATE函数会返回SQL执行的日期，由于没有参数，因此不需要使用括号，例如今天执行的结果即为'2020-11-06'。 #获取当前日期 #Postgre SQL, MySQL SELECT CURRENT_DATE; #SQL Server SELECT CAST(CURRENT_TIMESTAMP AS DATE) AS CUR_DATE; #Oracle SELECT CURRENT_DATE FROM dual; #DB2 SELECT CURRENT DATE FROM SYSIBM.SYSDUMMY1; 这个函数在不同RDBMS中区别较大，在SQL Server中只能用CURRENT_TIMESTAMP来获取完整时间再用CAST（之后会将）函数转化为DATE类型，在Oracle和DB2中需要指定临时表dual和SYSIBM.SYSDUMMY1。 ②CURRENT_TIME获取当前时间 类似CURRENT_DATE的功能，这个函数会返回程序执行的时间，例如现在是10:34:10。 #获取当前时间 #Postgre SQL, MySQL SELECT CURRENT_TIME; #SQL Server SELECT CAST(CURRENT_TIMESTAMP AS TIME) AS CUR_TIME; #Oracle SELECT CURRENT_TIMESTAMP FROM dual; #DB2 SELECT CURRENT TIME FROM SYSIBM.SYSDUMMY1; 这个函数在不同RDBMS的区别和CURRENT_DATE差不多。 ③CURREN_TIMESTAMP当前日期和时间 这个函数具有①+②的功能，即可以获取当前的年月日时分秒。 #获取当前的完整时间 #Postgre SQL, MySQL, SQL Server SELECT CURRENT_TIMESTAMP; #Oracle SELECT CURRENT_TIMESTAMP FROM dual; #DB2 SELECT CURRENT TIMESTAMP FROM SYSIBM.SYSDUMMY1; 区别同上，就不多说了。 ④EXTRACT函数截取日期元素 CURRENT_TIMESTAMP函数得到的是年月日时分秒，可以用EXTRACT函数按需求查询年、月、日等...，同时注意这个函数的返回值的类型是数值型不再是日期型了。 #分别查询当前完整时间的年月日时分秒 #Postgre SQL, MySQL SELECT CURRENT_TIMESTAMP, EXTRACT(YEAR FROM CURRENT_TIMESTAMP) AS year, EXTRACT(MONTH FROM CURRENT_TIMESTAMP) AS month, EXTRACT(DAY FROM CURRENT_TIMESTAMP) AS day, EXTRACT(HOUR FROM CURRENT_TIMESTAMP) AS hour, EXTRACT(MINUTE FROM CURRENT_TIMESTAMP) AS minute, EXTRACT(SECOND FROM CURRENT_TIMESTAMP) AS second; #SQL Server SELECT CURRENT_TIMESTAMP, DATEPART(YEAR FROM CURRENT_TIMESTAMP) AS year, DATEPART(MONTH FROM CURRENT_TIMESTAMP) AS month, DATEPART(DAY FROM CURRENT_TIMESTAMP) AS day, DATEPART(HOUR FROM CURRENT_TIMESTAMP) AS hour, DATEPART(MINUTE FROM CURRENT_TIMESTAMP) AS minute, DATEPART(SECOND FROM CURRENT_TIMESTAMP) AS second; #Oracle SELECT CURRENT_TIMESTAMP, EXTRACT(YEAR FROM CURRENT_TIMESTAMP) AS year, EXTRACT(MONTH FROM CURRENT_TIMESTAMP) AS month, EXTRACT(DAY FROM CURRENT_TIMESTAMP) AS day, EXTRACT(HOUR FROM CURRENT_TIMESTAMP) AS hour, EXTRACT(MINUTE FROM CURRENT_TIMESTAMP) AS minute, EXTRACT(SECOND FROM CURRENT_TIMESTAMP) AS second FROM dual; #DB2 SELECT CURRENT TIMESTAMP, EXTRACT(YEAR FROM CURRENT_TIMESTAMP) AS year, EXTRACT(MONTH FROM CURRENT_TIMESTAMP) AS month, EXTRACT(DAY FROM CURRENT_TIMESTAMP) AS day, EXTRACT(HOUR FROM CURRENT_TIMESTAMP) AS hour, EXTRACT(MINUTE FROM CURRENT_TIMESTAMP) AS minute, EXTRACT(SECOND FROM CURRENT_TIMESTAMP) AS second FROM SYSIBM.SYSDUMMY1; 这个函数在SQL Server中又用不了，SQL Server中同样功能的函数叫DATEPART。Oracle和DB2用法一样只需要加个FROM 临时表;即可。 6.1.5 转换函数 转换函数比较少也好理解，主要功能是转换数据类型或者转换数据值。 ①CAST类型转换函数 CAST函数的用法为CAST(数据 AS 想要转换的数据类型)，下面是例子： #将'0001'转换为数值型 #SQL Server，PostgreSQL SELECT CAST('0001' AS INTEGER) AS int_col; #MySQL SELECT CAST('0001' AS SIGNED INTEGER) AS int_col; #Oracle SELECT CAST('0001' AS INTEGER) AS int_col FROM DUAL; #DB2 SELECT CAST('0001' AS INTEGER) AS int_col FROM SYSIBM.SYSDUMMY1; 区别就不说了，已经说累了。注意MySQL的数据类型要写成SIGNED INTEGER即可。下面再看个例子： #将字符串'2009-12-14'转换为日期 #SQL Server，PostgreSQL,MySQL SELECT CAST('2009-12-14' AS DATE) AS date_col; #Oracle SELECT CAST('2009-12-14' AS DATE) AS date_col FROM DUAL; #DB2 SELECT CAST('2009-12-14' AS DATE) AS date_col FROM SYSIBM.SYSDUMMY1; ②COALESCE将NULL值转化为其他值 COALESCE是SQL特有的函数，其语法为COALESCE(数据1，数据2....)，该函数会返回可变参数中从左数第一个不是NULL的值。例如： #COALESCE的用法 #SQL Server，PostgreSQL,MySQL SELECT COALESCE(NULL,1) AS col_1, COALESCE(NULL,'test',NULL) AS col_2, COALESCE(NULL,NULL,'2009-11-01') AS col_3; #Oracle SELECT COALESCE(NULL,1) AS col_1, COALESCE(NULL,'test',NULL) AS col_2, COALESCE(NULL,NULL,'2009-11-01') AS col_3 FROM DUAL; #DB2 SELECT COALESCE(NULL,1) AS col_1, COALESCE(NULL,'test',NULL) AS col_2, COALESCE(NULL,NULL,'2009-11-01') AS col_3 FROM SYSIBM.SYSDUMMY1; 上面的例子只是展示功能和不同RDBMS的用法区别，其实COALESCE函数可以将列中的NULL值转化为其他值，例如想把str1中的NULL值转化为'cbconne'，则如下： #把str1中的NULL值转化为'cbconne' SELECT COALESCE(str1,'cbconne') AS col_1 FROM samplestr; 如上可以将NULL值转化为需要的值，方便使用函数或者进行运算。初见如果觉得这个函数比较不好理解，建议自己上手试几个例子就明白了！ 今天学完了6.1。 ","link":"https://wangykonne.github.io/post/sql-xue-xi-bi-ji-jiu/"},{"title":"SQL学习笔记（八）","content":" 学习用书：SQL基础教程（Mick著） 数据库：MySQL 数据库可视化软件：SQLyog 第五章：复杂查询 5.2 子查询 5.2.1 子查询和视图 一言以蔽之，子查询就是一次性视图（SELECT语句），与视图不同，子查询在SELECT语句执行完毕后就会消失。首先先复习一下昨天学习的视图查询的方法： #创建视图productsum CREATE VIEW productsum (product_type, cnt_product) AS SELECT product_type, COUNT(*) FROM product GROUP BY product_type; #查询视图内所有数据 SELECT * FROM productsum; 子查询能够实现同样的功能，只要将定义视图的SELECT语句直接用于查询的FROM语句中即可，但由于子查询是一次性的所以子查询的名称不会保存： #使用子查询实现同样的功能 #除Oracle之外的RDBMS SELECT * FROM (SELECT product_type, COUNT(*) FROM product GROUP BY product_type) AS productsum; #Oracle SELECT * FROM (SELECT product_type, COUNT(*) FROM product GROUP BY product_type) productsum; 上面的代码可以得到一模一样的结果，但是这里productsum是一个子查询而不是视图，因此这个临时的&quot;表&quot;不会储存在硬盘中，在SQL的视图框中找不到它的名字。注意Oracle中要去掉FROM 后面的AS。上面代码是一个嵌套结构，先执行括号里面的SELECT语句再执行外面的SELECT语句，所以可以设计多层嵌套的子查询，如下： #多层子查询 #除Oracle外的RDBMS SELECT * FROM (SELECT * FROM (SELECT product_type, COUNT(*) AS cnt_product FROM product GROUP BY product_type) AS productsum WHERE cnt_product = 4) AS productsum2; #Oracle SELECT * FROM (SELECT * FROM (SELECT product_type, COUNT(*) AS cnt_product FROM product GROUP BY product_type) productsum WHERE cnt_product = 4) productsum2; 上面的代码很好理解，就是先从product表中按product_type分组查询不同product_type对应的总数，再查询总数为4的product_type。这种多层嵌套可以继续嵌套下去，执行顺序都是从内到外，但层数越多越难读懂，所以只在有需要的时候用。最后，子查询不会保存，所以在写子查询的名字时一定要想一个合理好懂能表现代码意义的名字方便后来人阅读。 5.2.2 标量子查询 标量子查询是子查询的一种，不同之处在于，标量子查询限制返回的结果只能是一行一列的结果即一个数值。首先通过问题来引出标量子查询，例如，想查询出销售单价高于平均销售单价的商品。这个问题没有分组查询，不能用GROUP BY，从而不能用HAVING，那像下面这样写吗？ #查询出销售单价高于平均销售单价的商品的id，名称和销售价格 SELECT product_id, product_name, sale_price FROM product WHERE sale_price &gt; AVG(sale_price); 显然是不对的，因为WHERE语句不能使用聚合函数。究竟什么样的SELECT语句才能满足条件呢？这时标量子查询就派上用场了。由于AVG(sale_price)是一个标量常数，所以可以直接用一个标量子查询代替它，从而在WHERE子句中没有聚合函数，就可以执行了： #查询出销售单价高于平均销售单价的商品的id，名称和销售价格 SELECT product_id, product_name, sale_price FROM product WHERE sale_price &gt; (SELECT AVG(sale_price) FROM product); 同子查询一样，标量子查询的执行顺序也是按括号由内到外。 5.2.3 标量子查询的书写位置 标量子查询的书写位置不仅仅局限于WHERE中，只要能够使用常数或者列名的地方，几乎所有的子句都能够使用。例如在SELECT主句中使用标量子查询： #在SELECT主句中使用标量子查询 SELECT product_id, product_name, sale_price, (SELECT AVG(sale_price) FROM product) AS avg_price FROM product; 又例如在HAVING子句中使用标量子查询： #在HAVING子句中使用标量子查询 SELECT product_type, AVG(sale_price) FROM product GROUP BY product_type HAVING AVG(sale_price) &gt; (SELECT AVG(sale_price) FROM Product); 5.2.4 使用标量子查询的注意事项 标量子查询的注意事项只有一个，就是标量子查询返回的结果只能有一行一列的一个值。所以在写含有标量子查询的嵌套时，务必先执行标量子查询看看结果是不是只有一个值，再写嵌套。 5.3 关联子查询 5.3.1 普通子查询和关联子查询的区别 在上节，我们使用了子查询来查询了销售单价高于全部商品平均销售单价的商品，这次来看另一个例子，查询各种不同商品种类中销售单价高于该商品种类平均销售单价的商品，即对每个商品种类计算其平均销售单价，再在每个种类内进行比较。这个问题是以不同种类的组为基础而不是以全部商品为基础： #使用子查询解决上面的问题？ SELECT product_id, product_name, sale_price FROM product WHERE sale_price &gt; (SELECT AVG(sale_price) FROM product GROUP BY product_type); 遗憾的是，上面的代码并不正确，因为该子查询会返回三行结果，而WHERE中只能使用标量子查询。此时就该用到关联子查询了，只需在上面的子查询代码中加入一行就能得到正确的结果： #使用关联子查询解决上面的问题 #除Oracle外的RDBMS SELECT product_id, product_name, sale_price FROM product AS P1 WHERE sale_price &gt; (SELECT AVG(sale_price) FROM product AS P2 WHERE P1.product_type = P2.product_type GROUP BY product_type); #Oracle SELECT product_id, product_name, sale_price FROM product P1 WHERE sale_price &gt; (SELECT AVG(sale_price) FROM product P2 WHERE P1.product_type = P2.product_type GROUP BY product_type); 上面代码中起到关键作用的就是子查询中的WHERE语句的条件，该条件说明在同一商品种类进行平均值的比较，而FROM 的两个表都是product所以进行了取别名P1和P2，再用表名.列名的形式表示不同表的列。在细分的组内进行比较时，需要使用关联子查询。 5.3.2 关联子查询也是用来对集合切分的 其实，上面的代码去掉最后的GROUP BY语句也能得到一样的结果，原因就是关联子查询也是对集合的一种切分，对于子查询中的WHERE条件，每一中商品类别都会返回唯一一行的AVG值，这就是关联子查询不会出错的关键，它相当于对于每个分类都是一个标量子查询。 5.3.3 结合条件一定要写在子查询中 上面的代码有两个WHERE，那可以用AND把两个WHERE连接起来吗？例如： #错误示例 SELECT product_id, product_name, sale_price FROM product AS P1 WHERE P1.product_type = P2.product_type AND sale_price &gt; (SELECT AVG(sale_price) FROM product AS P2 GROUP BY product_type); 答案是不可以，因为上面代码违反了关联函数的作用域。前面已经说过，子查询会先于主查询执行，且不会保存结果表，因此上面的SELECT执行完后，P2表就会被删除，只会留下执行结果，所以WHERE中的P2表也就找不到对象了。具体来说，子查询内部设定的关联名称只能在内部使用，类似于函数定义的实参和形参。 第五章完结，复杂查询中的视图、子查询已经全部结束了。 ","link":"https://wangykonne.github.io/post/sql-xue-xi-bi-ji-ba/"},{"title":"SQL学习笔记（七）","content":" 学习用书：SQL基础教程（Mick著） 数据库：MySQL 数据库可视化软件：SQLyog 第五章：复杂查询 5.1 视图 5.1.1视图和表 下面进入新的工具——视图的学习，在SQL中不太需要区分视图和表，只需要知道它们的区别和更新时的一些不同即可。视图和表的区别就是是否保存了实际的数据。通常在创建表时，会通过INSERT语句将数据保存在数据库，这些数据会被真的保存到计算机的硬盘上，因此使用SELECT语句实际上相当于从硬盘中读取数据。但是使用视图不会将数据保存到任何地方，实际上视图里储存的是SELECT语句，因此从视图中读取数据时，会在内部执行SELECT语句并创建一张临时表。 视图的优点有两个。首先，由于视图不需要保存数据，因此可以节省储存设备的容量，例如在4.1节创建了用来汇总商品种类的销售总价和进货总价的表，表中的数据会占用储存空间，但使用视图只要把这段SELECT语句储存到视图中就可以了。其次，将需要频繁使用的SELECT语句保存为视图可以显著提高查询的效率，并且视图中的数据会随着原表的变化自动更新，而表中的数据需要手动更新。 5.1.2 创建视图的方法 创建视图需要使用CREATE VIEW 语句，基本语法为：CREATE VIEW 视图名称(列名...) AS (SELECT语句);。注意SELECT语句中的列顺序要和视图的列顺序对应。下面来试着创建一个视图： #创建视图查询Product表的所有商品种类及它们的总数 CREATE VIEW ProductSum (product_type, cnt_product) AS SELECT product_type, COUNT(*) FROM Product GROUP BY product_type; 上面代码的第二行的AS和取别名的AS不一样，不能省略。下面来试着使用这个视图，例如查看这个视图： #查看视图中的所有数据 SELECT * FROM ProductSum; 通过视图来封装需要频繁使用的语句可以在之后的查询中简化查询语句，并且只要Product表数据更新了，那么视图ProductSum的数据也会自动地更新。在使用视图进行查询时通常需要执行两个以上的SELECT语句，首先要执行定义视图的SELECT语句，再执行主体查询SELECT语句，同时视图还能以视图为基础创建，例如再创建一个视图查询视图ProductSum中product_type为办公用品的数据： #创建一个视图查询视图ProductSum中product_type为办公用品的数据 CREATE VIEW ProductSumJim (product_type, cnt_product) AS SELECT * FROM ProductSum WHERE product_type = '办公用品'; 但以视图创建视图要尽量避免，因为会降低SQL的运算性能。 5.1.3 视图的限制 ①不能使用ORDER BY子句。在定义视图中几乎可以用学过的所有SELECT语句，但不能使用ORDER BY语句。例如下面的视图定义会出现错误： #错误示例① CREATE VIEW ProductSum (product_type, cnt_product) AS SELECT product_type, COUNT(*) FROM Product GROUP BY product_type ORDER BY product_type; 注意有些RDBMS中可以使用ORDER BY（如PostgreSQL），但这不是通用的做法。所以在定义视图中尽量不要使用ORDER BY语句。 ②对视图进行更新。视图和表一样使用，那对于INSERT,DELETE,UPDATE这类更新语句该怎么使用呢？在标准SQL中，有规定：如果定义视图的SELECT语句满足以下条件就能进行更新： 1.SELECT语句没使用DISTINCT。 2.FROM子句只有一张表。 3.未使用GROUP BY和HAVING子句。 例如上面的视图ProductSum就不能通过INSERT INTO ProductSum VALUES ( );进行插入新数据的操作，因为ProductSum的定义是通过GROUP BY子句得到的。总之，记住一个法则：视图和表需要同时更新，如果一方更新后另一方的数据会出错则不能更新。 最后来看一个可以更新的视图例子： #除PostgreSQL以外的RDBMS #创建一个不使用聚合汇总得到的视图 CREATE VIEW ProductJim (product_id, product_name, product_type, sale_price, purchase_price, regist_date) AS SELECT * FROM productcopy WHERE product_type = '办公用品'; #向视图中添加新的数据 INSERT INTO ProductJim VALUES ('0009', '印章', '办公用品', 95, 10, '2009-11-30'); 上面代码的结果不仅会更新视图ProductJim，同时也会把新的数据插入到表productcopy中，因为视图和表是同时更新的。注意，在PostgreSQL中视图会被初始设定为只读，故上面的代码不能直接执行，需要先执行： #允许PostgreSQL对视图进行更新的操作 CREATE OR REPLACE RULE insert_rule AS ON INSERT TO ProductJim DO INSTEAD INSERT INTO Product VALUES( new.product_id, new.product_name, new.product_type, new.sale_price, new.purchase_price, new.regist_date); 5.1.4 删除视图 删除视图要使用DROP VIEW语句；删除表要使用DELETE FROM语句，不要记混淆了。例如想要删除视图ProductJim，如下： #删除视图ProductJim DROP VIEW ProductJim; 在PostgreSQL中，删除以视图为基础创建的多重视图时会出现以下错误，需要使用新的代码： #删除关联的视图 DROP VIEW ProductJim CASCADE; 5.1节结束~ ","link":"https://wangykonne.github.io/post/sql-xue-xi-bi-ji-qi/"},{"title":"漫长的夜","content":" 又到冬至了，魔幻的2020年终于也要落幕了。 早晨起床，看到大学的宿舍群里二战的xdm在讨论肖四题目。翻翻日历，哦原来已经21号了呀，聊天框里熟悉的那些政治术语不由得也把我拉进回忆中。就已经...一年了吗？是啊，这一年过的真的好快啊，突然比较好奇去年这个时候我在干什么（嘛应该是考完了两门在宾馆跟基友们聊天吧hh），于是翻开了手机的备忘录： 哈哈哈好蠢，着实把我看笑了😂，莫名有种动漫里勇者去打boss的战前演讲的感觉hh。不过遗憾的是去年和我一起备考的小伙伴们全部沉了，当时还难过了一阵子，现实中也许确实不存在所有人都幸福的HE，但还是希望我在意的人们能够实现愿望呀~所以，今年一定要上岸啊大伙！！ 吃饺子了吗？ 冬至要吃饺子。虽然貌似南方没有这个习俗，我还是去找了找学校好吃的饺子。可惜最后还是没吃，因为二餐的那家真心感觉一般般而且还很小...想念以前家里奶奶包的饺子，小时候一口气能吃十来个（超大），唉说起来就会想回家了，然而还不知道实习是啥时候才放假呢😭 虽然没吃上饺子满足一下仪式感，但买了杯茶百道喝，尝到了新的好喝的奶茶，豆乳玉麒麟yyds！除了20起送着实有点贵而且室友一般不喝我自己得点大杯还要加料才能凑齐...不过味道真的太棒了！甜甜的奶茶让大脑释放更多的多巴胺，试图忘记数理金融生存分析明天考试这件事（警觉 结课咯~ 忙碌的研一上学期要结束咯~ 不得不说这个学期收获还是很大的！每门课都能学到东西，也许有些并没什么用，但学习也不是奔着功利化去的嘛，不过除了自闭英语课hh，我真是presentation废物本废了，站上台就紧张呜呜呜。忙完这阵子就能好好休息一下了，嗯已经开始期待元旦和发小去逛cp买买买了（方舟同人我来了！）。同时，马上也要开始实习了，也不知道早高峰能不能顶得住...但能找到地方收留还是很好滴~ 一切还是在自己的规划上（虽然可能前进地比较慢），加油呀！wyk~ 关掉月亮进入梦乡 一年中最漫长的夜晚，希望能睡个舒服的懒觉哈哈，忘掉最近的一些糟心事，今夜好梦~ ","link":"https://wangykonne.github.io/post/zui-man-chang-de-ye/"},{"title":"SQL学习笔记（六）","content":" 学习用书：SQL基础教程（Mick著） 数据库：MySQL 数据库可视化软件：SQLyog 第四章：数据更新 4.4 事务 4.4.1 什么是事务 在RDBMS中，事务就是对表中数据更新的单位，简单来说，事务就是需要在同一个处理单元中执行的一系列更新处理的集合。在实际生活中，前面学过的INSERT,DELETE,UPDATE等更新处理往往不是只使用一次，而是要连续执行一系列更新处理。例如要将运动T恤的价格下调1000，T恤的价格上调1000，如果按前面学过的UPDATE需要使用两次： #将运动T恤的价格下调1000 UPDATE Product SET sale_price = sale_price - 1000 WHERE product_name = '运动T恤'; #将T恤的价格上调1000 UPDATE Product SET sale_price = sale_price + 1000 WHERE product_name = 'T恤衫'; 上面的代码属于两个处理单元，简单来说就是不能做到同时进行两种更新操作。使用事务可以使代码更美观且在一个处理单元中完成所有的更新处理操作。 4.4.2 创建事务 在SQL中事务的基本语法为：事务开始语句+DML语句若干+事务结束语句。使用事务开始和结束语句将更新处理DML语句括起来，就实现了一个事务处理。这里需要注意的是事务的开始语句，在不同的RDBMS中其语法不同： #事务开始的语句 #SQL Server,PostgreSQL BEGIN TRANSACTION; #MySQL START TRANSACTION; #Oracle,DB2 无 而事务结束的语句在所有RDBMS中都是相同的，即COMMIT;或者ROLLBACK;（两者含义有差别）。下面使用事务进行上面说的两种更新操作： #使用事务同时进行将运动T恤的价格下调1000、T恤的价格上调1000的操作 #MySQL START TRANSACTION; UPDATE Product SET sale_price = sale_price - 1000 WHERE product_name = '运动T恤'; UPDATE Product SET sale_price = sale_price + 1000 WHERE product_name = 'T恤衫'; COMMIT; #SQL Server,PostgreSQL BEGIN TRANSACTION; UPDATE Product SET sale_price = sale_price - 1000 WHERE product_name = '运动T恤'; UPDATE Product SET sale_price = sale_price + 1000 WHERE product_name = 'T恤衫'; COMMIT; #DB2,Oracle UPDATE Product SET sale_price = sale_price - 1000 WHERE product_name = '运动T恤'; UPDATE Product SET sale_price = sale_price + 1000 WHERE product_name = 'T恤衫'; COMMIT; COMMIT是提交事务包含的全部更新处理的结束指令，相当于文件处理中的覆盖保存。一旦提交就无法回到事务开始的状态了；而ROLLBACK是取消事务包含的全部更新的结束指令，相当于文件处理中的取消保存，即使用ROLLBACK后事务里的DML语句都不会执行，数据库会恢复到事务开始之前的状态。例如： #MySQL START TRANSACTION; UPDATE Product SET sale_price = sale_price - 1000 WHERE product_name = '运动T恤'; UPDATE Product SET sale_price = sale_price + 1000 WHERE product_name = 'T恤衫'; ROLLBACK; 上面的操作以ROLLBACK结尾，所以不会执行DML语句，运动T恤和T恤衫的价格都不会改变。 4.4.3 事务何时开始 事务开始指令在不同的RDBMS中不同，且DB2和Oracle没有事务开始指令。实际上几乎所有的数据库产品都可以不用事务开始指令，因为事务在建立链接时就会自动开始。那么既然不用事务开始指令怎么区别各个不同的事务呢？通常RDBMS有下面两种模式： ①每条SQL语句就是一个事务（自动提交模式） ②直到用户执行一个COMMIT或者ROLLBACK为止算一个事务 SQL Server,PostgreSQL,MySQL默认都使用模式①，即每条语句都会在执行时自动被BEGIN和COMMIT括起来而不显示；而Oracle默认使用模式②，事务都是直到用户写了事务结束指令才会结束。对于模式①需要注意的是DELETE语句，如果不是模式①，即使使用了DELETE误删了数据，也可以通过ROLLBACK进行回滚恢复数据；而在自动提交模式中使用了DELETE就再也无法恢复数据了只能重新插入。 4.4.4 ACID特性 RDBMS的事务都遵从四种特性，称为ACID特性，具体如下： 原子性（Atomicity） 原子性是指在事务结束时，其中所有的DML语句要么是全部执行要么是全部不执行，分别对应COMMIT和ROLLBACK语句。 一致性（Consistency） 一致性是指事务中的DML语句要满足数据库设置的约束，如NOT NULL约束、主键约束等。如果写了不合法的DML语句，则这些不合法的DML语句会被回滚即不执行，而其他合法的会继续执行下去（仅针对COMMIT结尾的事务）。 隔离性（Isolation） 隔离性是指不同事务之间互不干扰的特性，这保证了不同事务之间不能互相嵌套，即在某个事务中进行的操作，在该事务结束前对别的事务是不可见的。例如在某个事务中插入了一个新数据，那么只要这个事务没提交，在其他事务中这个新数据就是不存在的。 耐久性（Durability） 耐久性指的是在事务（不论是提交还是回滚）结束后，RDBMS会保证这个时间点的数据状态被保存。即使由于系统故障导致数据丢失，数据库也会自动恢复。 因为后天要期中考，今天摸鱼只完结了第四章，明天尽量从复习里抽点时间学点第五章。最后要说的是，学完这四章，对于SQL最基础的增删改查的学习就已经结束了，第五章之后可以说就是中阶的SQL了，开冲。（明天两门期末我害搁着搬运，老摸鱼哥了） ","link":"https://wangykonne.github.io/post/sql-xue-xi-bi-ji-liu/"},{"title":"SQL学习笔记（五）","content":" 学习用书：SQL基础教程（Mick著） 数据库：MySQL 数据库可视化软件：SQLyog 第四章：数据更新 4.1 数据的插入 4.1.1 INSERT语句的基本用法 在第一章创建数据库CREATE DATABASE，创建表CREATE TABLE时，运用了INSERT向表中插入数据，但当时没有介绍INSERT的详细使用方法。INSERT语句的基本用法如下，下面的ProductIns是为了这一节学习创建的空表，列和Product一样： #创建学习用空表ProductIns CREATE TABLE ProductIns (product_id CHAR(4) NOT NULL, product_name VARCHAR(100) NOT NULL, product_type VARCHAR(32) NOT NULL, sale_price INTEGER DEFAULT 0, purchase_price INTEGER , regist_date DATE , PRIMARY KEY(product_id)); #向表中插入一列数据 INSERT INTO ProductIns (product_id, product_name, product_type, sale_price, purchase_price, regist_date) VALUES ('0001', 'T恤衫','衣服', 1000, 500, '2009-09-20'); 上面显示的INSERT的用法是最基础的，即INSERT INTO 表名 (列名) VALUES (值)，注意值的个数要和列名的个数一致。当同时插入多行数据时，有简便的语法形式，如下： #多行INSERT(Oracle除外) INSERT INTO ProductIns VALUES ('0002', '打孔器', '办公用品', 500, 320, '2009-09-11'), ('0003', '运动T恤', '衣服', 4000, 2800, NULL), ('0004', '菜刀', '厨房用具', 3000, 2800, '2009-09-20'); #Oracle的多行INSERT INSERT ALL INTO ProductIns VALUES ('0002', '打孔器', '办公用品', 500, 320, '2009-09-11') INTO ProductIns VALUES ('0003', '运动T恤', '衣服', 4000, 2800, NULL) INTO ProductIns VALUES ('0004', '菜刀', '厨房用具', 3000, 2800, '2009-09-20') SELECT * FROM DUAL; 上面的代码第一段比较好理解，就是省略了一些结构性的语句。第二段中的DUAL表是Oracle特有的一种临时表，SELECT * FROM DUAL并没有什么实际意义。 4.1.2 列清单的省略 上一节的代码中，其实已经采用了省略列清单的语句进行INSERT，这种语法很好理解，SQL会将值从左到右赋给从左到右的每一个列。所以在INSERT时，只要注意输入值的顺序就可以省略列清单。 4.1.3 插入NULL 想要在表中插入NULL值很简单，直接把值写为NULL即可，唯一要注意的就是列是否有NOT NULL的限制。 4.1.4 插入默认值 还可以在表中插入默认值，首先要在CREATE TABLE语句时设置DEFAULT约束来设置默认值。如第一节的代码中设置了sale_price的默认值为0。插入默认值的方法分为两种，显式和隐式： #显式方法插入默认值 INSERT INTO ProductIns VALUES ('0007', '擦菜板', '厨房用具', DEFAULT, 790, '2209-04-28'); 显式方法直接把值写为DEFAULT即可，隐式方法只要同时省略列和对应的值即可将该列设置为默认值，如下在列清单中省略sale_price在值清单中省略其值，也可设置默认值： #隐式方法插入默认值 INSERT INTO ProductIns (product_id, product_name, product_type, purchase_price, regist_date) VALUES ('0007', '擦菜板', '厨房用具', 790, '2209-04-28'); 实际使用中，显式方法用的更多，因为代码清晰简洁。最后有一点，不管用显式方法将没有设置默认值的列设置为DEFAULT还是用隐式方法胜率了没有设置默认值的列，都会将这列的值设置为NULL，如果恰好这列又有NOT NULL的限制则会出现错误。 4.1.5 从其他表中复制数据 下面来学习从其他表中复制数据，下面先创建一个和Product表结构完全一样的表ProductCopy： #创建学习用表ProductCopy CREATE TABLE ProductCopy (product_id CHAR(4) NOT NULL, product_name VARCHAR(100) NOT NULL, product_type VARCHAR(32) NOT NULL, sale_price INTEGER , purchase_price INTEGER , regist_date DATE , PRIMARY KEY (product_id)); 下面把Product的表直接复制到ProductCopy中，语句结构为INSERT INTO...SELECT...FROM...： #从Product表中复制所有数据到ProductCopy INSERT INTO ProductCopy (product_id, product_name, product_type, sale_price, purchase_price, regist_date) SELECT product_id, product_name, product_type,sale_price, purchase_price, regist_date FROM Product; 上面的代码用到了SELECT语句，事实上这个SELECT语句还可以使用WHERE子句或者GROUP BY子句和聚合函数，可以在复制数据时加入很多限制条件，例如，想在Product表中按product_type分类并计算sale_price和purchase_price的总值并将这三列数据复制到表Product_type中： #先创建一个Product_type表 CREATE TABLE Product_type (product_type VARCHAR(32) NOT NULL, sum_sale_price INTEGER , sum_purchase_price INTEGER , PRIMARY KEY(product_type)); #在Product表中按product_type分类并计算sale_price和purchase_price的总值并将这三列数据复制到表Product_type中 INSERT INTO Product_type (product_type, sum_sale_price, sum_purchase_price) SELECT product_type, SUM(sale_price), SUM(purchase_price) FROM Product GROUP BY product_type; 其实上面的代码也可以省略列清单，只要对应好值的顺序即可。最后，INSERT中的SELECT语句可以使用几乎所有已学的语法子句和函数，除了ORDER BY，排序语句在INSERT的SELECT中不起作用。 4.2 数据的删除 4.2.1 DROP TABLE语句和DELETE语句 这两个语句在第一章其实都用过，DROP TABLE会将表完全删除，再想用只能重新创建表；而DELETE会将表的所有数据删除但会保留表本身，故可以直接重新插入数据。这是它们的主要区别。 4.2.2 DELETE语句的基本语法 单独一个DELETE的用法很有限，只能删除表中所有的数据： #清空表Product DELETE FROM Product; DELETE语句要接FROM而不是TABLE，不要和DROP TABLE记混淆了。同时DELETE的删除对象是行，故不能进行只删除某些列的操作，并且DELETE * FROM xx也是错误的用法。 4.2.3 指定删除对象的DELETE语句 DELETE以行为对象，所以可以像SELECT一样使用WHERE语句进行指定条件，例如想删除Product表中sale_price大于等于4000的数据： #删除Product表中sale_price大于等于4000的数据 DELETE FROM Product WHERE sale_price &gt;= 4000; 与SELECT语句不同的是，DELETE语句不能使用GROUP BY、HAVING和ORDER BY这三种子句，只能使用WHERE语句，而WHERE语句中又不能使用聚合函数，所以DELETE也与聚合函数无关了，综上，DELETE语句的使用方法还是很简单且有限的。 4.3 数据的更新 4.3.1 UPDATE语句的基本语法 如果在INSERT语句插入数据后，有时还想更改数据，此时并不需要将数据完全删除，而可以使用UPDATE直接对数据进行更新，UPDATE的基本语法如下，UPDATE 表名 SET 列名=表达式;如下例子，将regist_date全部更新为'2009-10-10': #将regist_date全部更新为'2009-10-10' UPDATE Product SET regist_date = '2009-10-10'; 4.3.2 指定条件的UPDATE语句 同DETELE一样，UPDATE也有指定条件的用法，不然只有上面这种用法实在是太蠢了。指定条件同样使用了WHERE语句，如下将商品种类为厨房用具的记录的销售单价更新为原来的十倍： #将商品种类为厨房用具的记录的销售单价更新为原来的十倍 UPDATE Product SET sale_price = sale_price*10 WHERE product_type = '厨房用具'; 最后，UPDATE也可以将列的值更新为NULL，比较简单就不写例子了。 4.3.3 多列更新 如果要进行多列更新且这些UPDATE语句很相似时怎么办呢？如下，一条一条的输入： #将商品种类为厨房用具的记录的销售单价更新为原来的十倍 UPDATE Product SET sale_price = sale_price*10 WHERE product_type = '厨房用具'; #再将商品种类为厨房用具的记录的进货单价更新为原来的一半 UPDATE Product SET purchase_price = purchase_price/2 WHERE product_type = '厨房用具'; 上面的方法繁琐又增加了阅读量，可以合并为一条UPDATE语句执行，具体有两种方法： #多列更新方法①，使用逗号分割 UPDATE Product SET sale_price = sale_price*10, purchase_price = purchase_price/2 WHERE product_type = '厨房用具'; #多列更新方法②，将列用()清单化，方法②只适合PostgreSQL和DB2 UPDATE Product SET (sale_price, purchase_price) = (sale_price*10, purchase_price/2) WHERE product_type = '厨房用具'; 上面两种方法的结果是一样的，但第二种方法只适用于PostgreSQL和DB2系统，所以一般还是第一种方法最常用。 今天学习完毕，明天完结第四章最后一节（比较长），有时间再学点第五章。 ","link":"https://wangykonne.github.io/post/sql-xue-xi-bi-ji-wu/"},{"title":"SQL学习笔记（四）","content":" 学习用书：SQL基础教程（Mick著） 数据库：MySQL 数据库可视化软件：SQLyog 第三章：聚合与排序 3.3 为聚合结果指定条件 3.3.1 HAVING子句 昨天最后说到了一个例子，如果想取出GROUP BY分组后COUNT数恰好为2的组怎么办呢？WHERE语句不能使用聚合函数，所以这时就要采用HAVING子句了。下面是昨天的问题的解决方法： #按product_type分组并取出COUNT数恰好为2的类别 SELECT product_type, COUNT(*) FROM Product GROUP BY product_type HAVING COUNT(*) = 2; HAVING的语法为：HAVING语句写在GROUP BY语句之后，且语句的执行顺序也在GROUP BY之后。目前学过的所有语句的书写顺序暂时为： SELECT→FROM→WHERE→GROUP BY→HAVING 同样，HAVING语句也接受其他类型的聚合函数，例如想按product_type分组并取出sale_price的平均值大于等于2500的商品并记录其商品种类和avg值： #按product_type分组并取出sale_price的平均值大于等于2500的商品并记录其商品种类和avg值 SELECT product_type, AVG(sale_price) AS avg FROM Product GROUP BY product_type HAVING AVG(sale_price) &gt;= 2500; 3.3.2 HAVING子句的构成要素 HAVING子句和包含GROUP BY的SELECT子句一样，对子句内的元素有一定限制，限制也是完全一样的，即HAVING子句内能使用的元素只有①常数；②聚合函数；③GROUP BY子句中出现的列名。下面是一个会出现错误的例子： #错误示范① SELECT product_type, COUNT(*) FROM Product GROUP BY product_type HAVING product_name = '圆珠笔'; 3.3.3 与HAVING语句相比，更适合写在WHERE中的条件 也许有人已经发现了，当条件限制不是聚合函数时，HAVING和WHERE的功能似乎重合了。下面来看两个例子，均表示按product_type分类并选择product_type为衣服的类别并查询其COUNT，但一个使用HAVING，一个使用WHERE： #按product_type分类并选择product_type为衣服的类别并查询其COUNT，使用HAVING SELECT product_type, COUNT(*) FROM Product GROUP BY product_type HAVING product_type = '衣服'; #按product_type分类并选择product_type为衣服的类别并查询其COUNT，使用HAVING SELECT product_type, COUNT(*) FROM Product WHERE product_type = '衣服' GROUP BY product_type; 上面两段代码的结果是完全一样的，确实在不涉及聚合函数的限制条件时使用HAVING和WHERE是等价的，但书上建议使用WHERE，因为WHERE语句的执行速度比HAVING快。总结一下就是，当限制条件涉及使用聚合函数时使用HAVING，其他情况均使用WHERE。 3.4 对查询结果进行排序 3.4.1 ORDER BY子句 目前我们已经学习了各种的查询、限制条件、聚合函数、分组方法，下面来学习对查询结果进行排序。在SQL中，使用ORDER BY子句就可以对查询结果进行排序，很简单。下面看一个例子，例如按销售单价升序查询product_id,product_name,sale_price,purchase_price： #按销售单价升序查询product_id,product_name,sale_price,purchase_price SELECT product_id, product_name, sale_price, purchase_price FROM Product ORDER BY sale_price; 不论什么情况，ORDER BY子句都是写在SELECT语句的末尾（limit除外），同时执行顺序里ORDER BY也是在结果即将输出时进行排序。所以到目前为止，我们所学的所有子句的书写顺序暂时为： SELECT→FROM→WHERE→GROUP BY→HAVING→ORDER BY 3.4.2 指定升序或者降序 默认情况下ORDER BY子句是升序操作，可以在列名后加DESC关键字进行降序操作，当然升序也可以使用ASC关键字。下面试试上节一样的例子，这次采用降序排列： #按销售单价降序查询product_id,product_name,sale_price,purchase_price SELECT product_id, product_name, sale_price, purchase_price FROM Product ORDER BY sale_price DESC; 3.4.3 指定多个排序键 如果想指定多个排序规则，例如上面的例子中sale_price相等的商品可以再按照另一个排序键进行排序。同时ASC和DESC关键字都是以列为单位的，所以可以自定义使用来制定多种多样的排序规则。例如，按销售单价升序再按商品编号降序查询product_id,product_name,sale_price,purchase_price： #按销售单价升序再按商品编号降序查询product_id,product_name,sale_price,purchase_price SELECT product_id, product_name, sale_price, purchase_price FROM Product ORDER BY sale_price ASC, product_id DESC; 3.4.4 NULL的顺序 对于含有NULL值的列会怎么样进行排序呢，下面看一个例子，对进货单价升序查询product_id,product_name,sale_price,purchase_price： #按进货单价升序查询product_id,product_name,sale_price,purchase_price SELECT product_id, product_name, sale_price, purchase_price FROM Product ORDER BY purchase_price; 在我自己的MySQL中，结果的NULL值被全部放在了最开头的部分，但不是表示NULL比所有值都小。前面说过NULL不能进行四则运算也不能进行排序，所以所有的RDBMS都会规定在排序中统一把NULL放在最开头或者结尾的地方，具体是开头还是结尾视不同的RDBMS定，有的RDBMS还能指定开头或者结尾。至少在MySQL中是统一放在开头处。 3.4.5 在排序键中使用显示用的列别名 前面说过在GROUP BY子句中不能使用列的别名，但在ORDER BY子句中可以使用列的别名： #按销售单价升序再按商品编号降序查询product_id,product_name,sale_price,purchase_price，并把product_id改为id，sale_price改为sp SELECT product_id AS id, product_name, sale_price AS sp, purchase_price FROM Product ORDER BY sp ASC, id DESC; 上面代码和上上节的代码查询结果完全相同（除了别名）。ORDER BY子句可以使用别名的原因和语句的执行顺序有关，到目前为止，学过的所有子句的执行顺序暂时为： FROM→WHERE→GROUP BY→HAVING→SELECT→ORDER BY 可以看到ORDER BY位于SELECT之后，所以在SELECT写的别名可以被ORDER BY识别，而GROUP BY执行于SELECT之前所以不能识别SELECT写的别名。事实上所有执行早于SELECT的子句都不能使用别名。 3.4.6 ORDER BY子句中可以使用的列 ORDER BY子句内的元素使用范围比较宽泛，甚至在SELECT中没出现的列也可以作为ORDER BY子句的排序键： #按product_id升序查询product_name,sale_price,purchase_price SELECT product_name, sale_price, purchase_price FROM Product ORDER BY product_id; 上面的语句也可以执行，不过因为没有SELECT product_id，排序的效果会看不见所以不推荐这种方法。除此之外，ORDER BY还可以使用聚合函数： #按product_type分类并查询其COUNT，最后再按COUNT进行升序排序 SELECT product_type, COUNT(*) FROM Product GROUP BY product_type ORDER BY COUNT(*); 今天将第三章完结了，明天开始第四章数据更新的学习。 ","link":"https://wangykonne.github.io/post/sql-xue-xi-bi-ji-si/"},{"title":"SQL学习笔记（三）","content":" 学习用书：SQL基础教程（Mick著） 数据库：MySQL 数据库可视化软件：SQLyog 第二章：查询基础 2.3 逻辑运算符 2.3.1 NOT运算符 NOT运算符比较好理解，就是表示&quot;非&quot;的意思，使用范围比不等号&lt;&gt;要广，例如想要选择销售单价小于1000的商品时，就可以用NOT语句： #使用NOT查询sale_price小于1000的行的product_name,product_type,sale_price值 SELECT product_name, product_type, sale_price FROM Product WHERE NOT sale_price &gt;= 1000; 虽然直接用&lt;1000可以不用使用NOT，但上面例子只是展示一下用法，NOT语句在复杂的语法中会发挥它的作用。 2.3.2 AND运算符和OR运算符 实际生活中，往往查询中不止一个限制条件，此时就可以使用AND和OR运算符，分别表示且、或的概念。例如，想查询商品种类为厨房用品且销售单价大于等于3000的商品，可以使用AND： #查询product_type为'厨房用具'且sale_price不小于3000的行的product_name,purchase_price SELECT product_name, purchase_price FROM Product WHERE product_type = '厨房用具' AND sale_price &gt;= 3000; 想查询商品种类为厨房用品或者销售单价大于等于3000的商品，可以使用OR： #查询product_type为'厨房用具'或者sale_price不小于3000的行的product_name,purchase_price SELECT product_name, purchase_price FROM Product WHERE product_type = '厨房用具' OR sale_price &gt;= 3000; 2.3.3 通过括号强化处理 需要注意的是，AND运算符的优先级高于OR运算符，如果在混合使用中，可能会引起歧义，这时最好使用括号进行处理。例如想要查询商品种类为办公用品，并且，登记日期为2009-9-11或2009-9-20的商品： #查询product_type为'办公用品'且regist_date为'2009-09-11'或'2009-09-20'的行的product_name,product_type,regist_date SELECT product_name, product_type, regist_date FROM Product WHERE product_type = '办公用品' AND (regist_date = '2009-09-11' OR regist_date = '2009-09-20'); 上面的语句中，如果把括号去掉，会返回不一样的结果，因为AND的运算优先级高于OR，SQL会理解为&quot;product_type = '办公用品' AND regist_date = '2009-09-11'&quot; OR &quot;regist_date = '2009-09-20'&quot;。所以在混合使用时要注意使用括号。 2.3.4 含有NULL时的真值 在SQL中，逻辑运算符的结果除了TRUE和FALSE外，还有一个UNKNOWN，表示不确定值。即NULL值在和真假值进行AND和OR运算时，会产生UNKNOWN值，具体运算规则比较简单，直接想想就懂了。 第三章：聚合与排序 3.1 对表进行聚合排序 3.1.1 聚合函数 通过SQL对数据某些操作时需要使用函数。下面是5个基本的函数： COUNT：记录表中的行数（数据数） SUM：计算表中数据的各列的数据的总值。 AVG：计算表中数据的各列的平均值。 MAX：计算表中数据的各列的最大值。 MIN：计算表中数据的各列的最小值。 3.1.2 计算表中数据的行数 使用COUNT函数可以计算表中数据的行数，例如计算表中数据一共有多少行： #查询全部数据的行数 SELECT COUNT(*) FROM Product; 3.1.3 计算除NULL值以外的数据的行数 例如purchase_price列中含有NULL值，所以使用COUNT进行查询时，会返回非NULL值的行数： #查询purchase_price列中非NULL的行数 SELECT COUNT(purchase_price) FROM Product; 需要注意一个特殊情况，例如一个只有一列的表，其三行数据均为NULL，则用COUNT(*)查询时会返回3，但使用COUNT(列名)查询时会返回0！原因很简单，就是COUNT函数的原理问题，就不多介绍了。 3.1.4 计算合计值 使用SUM函数可以得到指定列的数据总值，例如求sale_price,purchase_price列的数据总和： #查询sale_price,purchase_price列的数据总和 SELECT SUM(sale_price), SUM(purchase_price) FROM Product; 需要注意的是，purchase_price中含有NULL值，为什么还会返回出计算的正确结果呢，按照昨天的学习NULL值进行四则运算一定会得到NULL值。原因是所有的聚合函数在以列名为参数时会自动先把NULL值的行排除在外，所以即使列内有NULL值也能使用聚合函数得到对应的结果。 3.1.5 计算平均值 使用AVG函数可以计算指定列的数据的平均值，例如求sale_price,purchase_price列的数据平均值： #查询sale_price,purchase_price列的数据平均值 SELECT AVG(sale_price), AVG(purchase_price) FROM Product; 上面说到，聚合函数以列名为参数时会忽略NULL值，所以此时计算平均数的分母也会发生变化，例如purchase_price中非NULL值为6行，所以平均值计算会除以6而不是除以8。当然也有方法把NULL视为0然后除以8计算平均值，这种方法会在第六章介绍。 3.1.6 计算最大值和最小值 使用MIN和MAX可以得到指定列的数据最大值和最小值，例如求sale_price的最小值和purchase_price的最大值： #查询sale_price的最小值和purchase_price的最大值 SELECT MIN(sale_price), MAX(purchase_price) FROM Product; 需要注意的是，MAX/MIN函数和SUM/AVG函数有一点不同，SUM/AVG函数只能对数值类型的列使用，但MAX/MIN函数原则上可以适用于任何类型的数据列，例如如果对字符串类型则会按字典排序的方法选择最大值和最小值： #查询登记日期的最大值和最小值 SELECT MIN(regist_date), MAX(regist_date) FROM Product; 3.1.7 使用聚合函数删除重复值 聚合函数和DISTINCT函数结合使用，如想知道一个列有几种不同的值： #查询product_type总共有多少种不同的取值 SELECT COUNT(DISTINCT product_type) FROM Product; 其他聚合函数和DISTINCT的用法类似，注意DISTINCT要放在聚合函数的括号内。 3.2 对表进行分组 3.2.1 GROUP BY子句 前面所学的各种语句都是对表中的所有数据进行的汇总处理。而使用GROUP BY语句可以将表分为多个组再进行汇总处理，例如，想按照商品种类来统计一下数据的行数： #按product_type查询数据的行数 SELECT product_type, COUNT(*) FROM Product GROUP BY product_type; GROUP BY子句中指定的列成为聚合键或者分组列，如上product_type有三种不同的类型故最后查询的结果分别为这三种类型的各自行数。同样GROUP BY也可以通过逗号分割指定多列。最后GROUP BY子句的书写位置有固定的规则，一定要写在FROM语句后面，而如果还有WHERE语句那就要在WHERE语句之后。目前学习的语法顺序暂定为： SELECT➡FROM➡WHERE➡GROUP BY 3.2.2 聚合键中包含NULL的情况 purchase_price中含有两个NULL，所以我们用它做GROUP BY实验，看会得到怎样的结果： #按照purchase_price统计数据行数 SELECT purchase_price, COUNT(*) FROM Product GROUP BY purchase_price; 上面的结果会将NULL也视为一个类别，即不确定，会在表中以空行的形式展现出来。 3.2.3 同时使用WHERE语句和GROUP BY语句 同时使用WHERE和GROUP BY子句时，会先用WHERE语句对数据进行过滤，再按照GROUP BY进行汇总处理，例如查询商品类别为衣服的数据并按照进货价格分类，显示其进货价格和数据量： #查询商品类别为衣服的数据并按照进货价格分类，显示其进货价格和数据量： SELECT purchase_price, COUNT(*) FROM Product WHERE product_type = '衣服' GROUP BY purchase_price; 上面代码的执行顺序为：FROM→WHERE→GROUP BY→SELECT 3.2.4 与聚合函数和GROUP BY子句有关的常见错误 常见错误①：在SELECT子句中书写了不在聚合键中的列。 在使用COUNT这样的聚合函数时，SELECT子句的元素有很强的限制，只能存在以下三种成分：①常数，②聚合函数，③GROUP BY子句中指定的列名。下面给出一个错误的例子： #常见错误①的例子 SELECT product_name, purchase_price, COUNT(*) FROM Product GROUP BY purchase_price; 上面的代码中，SELECT语句的product_name没有包含在聚合键GROUP BY中，会出现错误。不支持这种语法的原因其实很好理解，因为按照GROUP BY分类后，类别数肯定是小于等于没分类的product_nam的行数的，这样表格就不是一对一的了，会出现问题，所以这种语法被禁止。 常见错误②：在GROUP BY子句中写了列的别名。 前面说过用SELECT AS 可以给列取别名，但如果在GROUP BY中使用这个别名来调用列就会出现错误： #常见错误②的例子 SELECT purchase_price AS pp, COUNT(*) FROM Product GROUP BY pp; 注意：上面的代码并非在所有RDBMS中都会产生错误，在PostgreSQL和MySQL中上面的语句是可以执行的，而在其他的RDBMS中则不能执行。在一些RDBMS中上面语句不能执行的原因很简单，就和之前说的语句执行顺序有关，GROUP BY会先于SELECT语句执行，故在SELECT中的别名不会被GROUP BY识别。尽管这种错误跟不同软件有关，但最好还是不要用这种语法了。 常见错误③：在WHERE语句中使用聚合函数。 先看一个正确的例子，按照商品类别进行分类： #按照商品类别进行分类并查询各类别的行数 SELECT product_type, COUNT(*) FROM Product GROUP BY product_type; 上面的代码的结果会返回三行数据，其中衣服和办公用品的COUNT都是2，厨房用具的COUNT是4。此时如果我们想查询COUNT数恰好为2的数据该怎么办呢？下面是一个错误的例子： #常见错误③的例子 SELECT product_type, COUNT(*) FROM Product WHERE COUNT(*) = 2 GROUP BY product_type; 理所当然地在WHERE中加入COUNT=2的选择条件是不行的，因为WHERE语句中不能使用聚合函数，要达到上面这个问题的目的需要使用HAVING子句。HAVING语句会在明天的3.3节中介绍。计划明天将第三章完结并做课后习题。 ","link":"https://wangykonne.github.io/post/sql-xue-xi-bi-ji-san/"},{"title":"SQL学习笔记（二）","content":" 学习用书：SQL基础教程（Mick著） 数据库：MySQL 数据库可视化软件：SQLyog 第二章：查询基础 2.1 SELECT语句基础 2.1.1 列的查询 从表中选取数据需要使用SELECT语句。SELECT语句的基本语法为： SELECT &lt;列名1&gt;,&lt;列名2&gt;... FROM &lt;表名&gt;; 这个语法非常简单，用昨天的Product表做个小例子： #查询Product表中的product_id,product_name,product_price三列的所有数据 SELECT product_id, product_name, purchase_price FROM Product; 最后，查询结果中列的顺序和SELECT子句的顺序相同，且不同列要用,隔开。 2.1.2 查询出表中所有的列 想要查询所有的列时，不需要按上面的方法把所有的列名都写出来，只需要用*代表所有的列： #查询Product中所有的列的所有数据 SELECT * FROM Product; 查询所有列时结果的列的顺序和创建表的列的顺序一致。 2.1.3 为列设置别名 SQL可以在SELECT中给列设置别名，语法和Python中的import as差不多，运用AS语句： #查询Product表中的product_id,product_name,product_price三列的所有数据，并将结果列名设置为id,name,price SELECT product_id AS id, product_name AS name, purchase_price AS price FROM Product; 别名也可以使用中文，不过要用双引号&quot;括起来，注意单引号'是不行的。 #查询Product表中的product_id,product_name,product_price三列的所有数据，并将结果列名设置为商品编号，商品名称，进货单价 SELECT product_id AS &quot;商品编号&quot;, product_name AS &quot;商品名称&quot;, purchase_price AS &quot;进货单价&quot; FROM Product; 2.1.4 常数的查询 SELECT的子句不仅可以书写列名，还可以书写常数，如下： #查询Product表中product_id,product_name列的所有数据，并在前面加入三个常数列，分别为商品，38，2009-02-24，别名为string,number,date SELECT '商品' AS string, 38 AS number, '2009-02-24' AS date, product_id, product_name FROM Product; 上面代码的结果会在product_id,product_name列前创建三个列名为string,number,date的列，这三个列的所有数据都为常数，分别对应'商品'，38，'2009-02-24'。 2.1.5 从结果中删除重复行 Product_type表示商品的种类，在表Product中存在一些重复的product_type，如果想知道表中一共有几种product_type时，可以在SELECT语句的子句中使用DISTINCT语句实现： #删除product_type列中的重复数据 SELECT DISTINCT product_type FROM Product; 在使用DISTINCT时，NULL值也会被看成一类，故不同行的NULL值也会被合并为一类。DISTINCT也可以在多列之前使用，此时会将多个列的数据进行组合，将重复的数据组合合并为一类。例如，下面的代码会选出7个数据： #删除product_type,regist_date列中的共同重复数据 SELECT DISTINCT product_type, regist_date FROM Product; 注意，DISTINCT关键字只能用在第一个列名前面，即不能写成product_type, DISTINCT regist_date。 2.1.6 根据WHERE语句来选择记录 前面的学习中，SELECT都是把所有数据全部选取出来，实际应用中，大部分情况是要选择满足一定特定条件的数据。使用WHERE语句可以指定查询的条件，例如：选取product_type为衣服的所有数据并输出它们的product_name： #选取product_type为衣服的所有数据并输出它们的product_name SELECT product_name, product_type FROM Product WHERE product_type = '衣服'; 上面代码的执行顺序为：首先WHERE语句先进行筛选出符合条件的所有行，再由SELECT选择对应的列。SQL的子句的书写顺序是固定的不能随意更改，WHERE子句必须紧跟在FROM子句之后。 2.1.7 注释的书写方法 和Python一样，SQL的注释分为一行注释和多行注释两种。 一行注释：书写在&quot;-- &quot;之后，只能写在同一行。 多行注释：书写在&quot;/*&quot;和&quot;*/&quot;之间，可以跨多行。 #注释的使用方法 #一行注释 -- 本SELECT语句会从结果中删除重复行 SELECT DISTINCT product_type, regist_date FROM Product; #多行注释 /* 本SELECT语句， 会从结果中删除重复行 */ SELECT DISTINCT product_type, regist_date FROM Product; 2.2 算术运算符和比较运算符 2.2.1 算术运算符 先看一个例子来理解怎么在SELECT中加入算术运算符： #选取product_name,sale_price列和sale_price的两倍命名为sale_price_x2 SELECT product_name, sale_price, sale_price*2 AS sale_price_x2 FROM Product; 其实算术运算符的用法很简单，就不再多说了。 2.2.2 需要注意NULL 在进行算术运算时，如果对象中包含NULL值会是什么结果呢？结果是NULL，所有包含NULL的计算结果均为NULL，甚至包括NULL/0也会是NULL。有时我们会希望NULL能像0一样进行计算，这种方法存在，但会在很后面才学习，先空在这里。 2.2.3 比较运算符 其实在WHERE语句的代码中，就使用了=这个比较运算符。下面来使用不等号&lt;&gt;，一个例子： #选择sale_price列的值不是500的记录的product_name,product_type值 SELECT product_name, product_type FROM Product WHERE sale_price &lt;&gt; 500; SQL的比较运算符和Python的基本一样，唯一有区别的就是不等号是&lt;&gt;。下面再给个算术运算符和比较运算符结合使用的例子： #选择sale_price-purchase_price大于等于500的列的product_name,sale_price,purchase_price值 SELECT product_name, sale_price, purchase_price FROM Product WHERE sale_price-purchase_price &gt;= 500; 2.2.4 对字符串使用不等号的注意事项 对于字符串中的数字使用各种大于小于号会怎么样呢？下面先创建一个字符串表： #创建一个字符串表Chars，并输入字符串类型的数字数据 CREATE TABLE Chars (chr CHAR(3) NOT NULL, PRIMARY KEY (chr)); START TRANSACTION; INSERT INTO Chars VALUES ('1'); INSERT INTO Chars VALUES ('2'); INSERT INTO Chars VALUES ('3'); INSERT INTO Chars VALUES ('10'); INSERT INTO Chars VALUES ('11'); INSERT INTO Chars VALUES ('222'); 下面来试着进行使用比较运算符，如查询chr列中大于'2'的数据会发生什么呢？ #查询chr列中大于'2'的数据 SELECT chr FROM Chars WHERE chr &gt; '2'; 上面代码的结果是不是'3'，'10'，'11'，'222'呢？答案不是，代码只返回了'3'和'222'。原因在于&gt; '2'部分表示与字符串'2'进行比较，所以不会按照数字的大小规则，而是按照字符串的大小规则进行比较，即先比较第一个字符显然只有'3'比'2'大，而'222'与'2'相同故比较第二个字符，'222'此时大于'2'，其他的均不满足条件。如果真的要对字符串数字进行比较运算，要使用数字类型。如下才会返回'3'，'10'，'11'，'222'。 #查询chr列中大于2的数据 SELECT chr FROM Chars WHERE chr &gt; 2; 2.2.5 不能对NULL使用比较运算符 关于比较运算符还有一点就是不能对NULL值使用比较运算符。例如，purchase_price中有NULL值，下面来查询purchase_price不为2800的记录： #查询purchase_price不等于2800的行的product_name,purchase_price值 SELECT product_name, purchase_price FROM Product WHERE purchase_price &lt;&gt; 2800; 上面代码的结果并没有输出NULL值，原因是NULL表示不明，即无法判断是否等于2800。那如果想选择purchase_price为NULL的记录怎么办呢？ #查询purchase_price为NULL值的行的product_name,purchase_price值 SELECT product_name, purchase_price FROM Product WHERE purchase_price = NULL; 非常遗憾，上面代码的结果是一条记录也取不出来，就算把=换成&lt;&gt;也是一样。因此SQL提供了专门用来判断是否为NULL的IS NULL运算符。想要选取为NULL值时，应该如下使用： #查询purchase_price为NULL值的行的product_name,purchase_price值 SELECT product_name, purchase_price FROM Product WHERE purchase_price IS NULL; 反之，如果想选择不是NULL值得记录时： #查询purchase_price不为NULL值的行的product_name,purchase_price值 SELECT product_name, purchase_price FROM Product WHERE purchase_price IS NOT NULL; 对NULL的其他运算符使用方法将在第六章详细介绍。今天学完了第二章前两节，明天完结第二章并继续第三章的学习。 ","link":"https://wangykonne.github.io/post/sql-xue-xi-bi-ji-er/"},{"title":"SQL学习笔记（一）","content":" 今天开始搬运以前写过的SQL学习笔记，尽量一天一更吧~ 学习用书：SQL基础教程（Mick著） 数据库：MySQL 数据库可视化软件：SQLyog 第一章：数据库与SQL 1.1 SQL概要 1.1.1 SQL语句及其种类 SQL用关键字、表名、列名等组合而成的一条SQL语句来描述操作的内容。根据对RDBMS赋予的指令种类的不同，SQL语句可分为以下三类： DDL（数据定义语言）用来创建或者删除数据库、表等对象。例如：①CREATE，创建数据库和表等对象；②DROP，删除数据库和表等对象；③ALTER，修改数据库和表等对象的结构。 DML（数据操纵语言）用来查询或者变更表中的记录。例如：①SELECT：查询表中的数据；②INSERT：向表中插入新的数据；③UPDATE：更新表中的数据；④DELETE：删除表中的数据。 DCL（数据控制语言）用来确认或者取消对数据库中的数据进行的变更，以及设定RDBMS的用户是否有权限操作数据库中的对象。例如：①COMMIT：确认对数据库中的数据进行的变更；②ROLLBACK：取消对数据库中的数据进行的变更；③GRANT：赋予用户操作权限；④REVOKE：取消用户的操作权限。 上述数据中，DML的使用率最高。 1.1.2 SQL的基本书写规则 SQL的语句要以半角分号;结尾。 SQL语句不区分关键字的大小写，例如SELECT和select的意义相同。但是，插入到表中的数据是区分大小写的，例如数据'computer'和'COMPUTER'是不一样的。 字符串形式的数据要用单引号'括起来；数字直接书写即可。 单词之间要使用半角空格或者换行符进行分割。 1.2 表的创建 1.2.1 数据库的创建 通过CREATE DATABASE 语句可以创建数据库，如下创建一个名为shop的数据库： CREATE DATABASE shop; 1.2.2 表的创建 创建好数据库后，使用CREATE TABLE 语句在其中创建表格，如下： CREATE DATABASE learning; CREATE TABLE Product (product_id CHAR(4) NOT NULL, product_name VARCHAR(100) NOT NULL, product_type VARCHAR(32) NOT NULL, sale_price INTEGER , purchase_price INTEGER , regist_date DATE , PRIMARY KEY (product_id)); 上面代码含义之后会讲解。 1.2.3 命名规则 只能使用半角英文字母、数字、下划线_作为数据库、表和列的名称；此外，名称必须用半角英文字母开头；最后不能创建相同名称的数据库或者表或者表中的列名。 1.2.4 数据类型的指定 上面代码中，Product表所包含的列，定义在（）内。其中CHAR(4)，VARCHAR(100)等是用来声明列的数据类型的。注意，所有列都必须声明数据类型，且每一列都不能储存和该列数据类型不符合的数据。四种基本的数据类型为： INTEGER：用来指定储存的数据类型为整数，不能储存小数。 CHAR：用来指定储存的数据类型为字符型，括号内的数字表示可储存的字符串的最大长度，且字符串会以定长的形式储存。例如在CHAR(8)中输入'abc'的时候会以'abc+五个半角空格'的形式保存起来。 VARCHAR：同CHAR类型一样，VARCHAR也是用来储存字符型数据的，不同之处在于VARCHAR是用可变长的形式储存字符串，不会像CHAR一样进行半角空格的补长。注意：Oracle中使用VARCHAR2表示这种类型 DATE：用来储存日期（年月日）的列的数据类型。注意：Oracle中的DATE型还包括时分秒 1.2.5 约束的设置 除了数据类型外，在列中储存数据有时还要进行限制或者追加条件。在上面的代码中，product_id，product_name，product_type列都设置了NOT NULL的设置，表示这三列的数据不能输入空白，即必须输入数据。 另外，在上面的代码的最后设置了PRIMARY KEY (product_id)，表示把product_id设置主键约束。通俗的理解就是：如果把product_id设置为主键，就可以通过该列的值唯一确定一行数据，即不同行数据的product_id必须是不一样的。 1.3 表的删除和更新 1.3.1 表的删除 删除表的语句非常简单，只要DROP TABLE 即可： DROP TABLE Product; 需要注意的是，删除的表是无法恢复的，只能重新创建重新插入数据。所以要执行DROP TABLE 语句的时候要仔细确认。 1.3.2 表定义的更新 有时候创建表后如果想继续加入几列或者删除其中几列时，不需要删除表再重新创建，只需要使用ALTER TABLE 语句，例如在Product表中加入一列product_name_pinyin储存100位可变长的字符串： #在Product表中加入一列product_name_pinyin储存100位可变长的字符串 #DB2,PostgreSQL,MySQL ALTER TABLE Product ADD COLUMN product_name_pinyin VARCHAR(100); #Oracle ALTER TABLE Product ADD (product_name_pinyin VARCHAR2(100)); #SQL Server ALTER TABLE Product ADD product_name_pinyin VARCHAR(100); 特定的SQL中，Oracle和SQL Server中不需要写COLUMN，Oracle中需要使用括号且VARCHAR应改为VARCHAR2。另外，Oracle可以一次同时添加多列，如： ALTER TABLE &lt;表名&gt; ADD (&lt;列名1&gt; VARCHAR2(100), &lt;列名2&gt; VARCHAR2(100)...); 反之，删除表中某些列如下，例如删除之前添加的product_name_pinyin列： #在Product表中删除product_name_pinyin列 #DB2,SQL Server,MySQL,Postgre SQL ALTER TABLE Product DROP COLUMN product_name_pinyin; #Oracle ALTER TABLE Product DROP (product_name_pinyin); 特定的SQL中，Oracle不需要写COLUMN，且可以通过上面一样的操作同时删除多列。 1.3.3 向Product表中插入数据 上面创建了数据库learning，表Product，但表内容是空的，下面来向表中插入数据： #向Product表中插入数据 #SQL Server,Postgre SQL BEGIN TRANSACTION; INSERT INTO Product VALUES ('0001', 'T恤衫', '衣服', 1000, 500, '2009-09-20'); INSERT INTO Product VALUES ('0002', '打孔器', '办公用品', 500, 320, '2009-09-11'); INSERT INTO Product VALUES ('0003', '运动T恤', '衣服', 4000, 2800, NULL); INSERT INTO Product VALUES ('0004', '菜刀', '厨房用具', 3000, 2800, '2009-09-20'); INSERT INTO Product VALUES ('0005', '高压锅', '厨房用具', 6800, 5000, '2009-01-15'); INSERT INTO Product VALUES ('0006', '叉子', '厨房用具', 500, NULL, '2009-09-20'); INSERT INTO Product VALUES ('0007', '擦菜板', '厨房用具', 880, 790, '2008-04-28'); INSERT INTO Product VALUES ('0008', '圆珠笔', '办公用品', 100, NULL, '2009-11-11'); COMMIT; #MySQL START TRANSACTION; INSERT INTO Product VALUES ('0001', 'T恤衫', '衣服', 1000, 500, '2009-09-20'); INSERT INTO Product VALUES ('0002', '打孔器', '办公用品', 500, 320, '2009-09-11'); INSERT INTO Product VALUES ('0003', '运动T恤', '衣服', 4000, 2800, NULL); INSERT INTO Product VALUES ('0004', '菜刀', '厨房用具', 3000, 2800, '2009-09-20'); INSERT INTO Product VALUES ('0005', '高压锅', '厨房用具', 6800, 5000, '2009-01-15'); INSERT INTO Product VALUES ('0006', '叉子', '厨房用具', 500, NULL, '2009-09-20'); INSERT INTO Product VALUES ('0007', '擦菜板', '厨房用具', 880, 790, '2008-04-28'); INSERT INTO Product VALUES ('0008', '圆珠笔', '办公用品', 100, NULL, '2009-11-11'); COMMIT; #Oracle,DB2 INSERT INTO Product VALUES ('0001', 'T恤衫', '衣服', 1000, 500, '2009-09-20'); INSERT INTO Product VALUES ('0002', '打孔器', '办公用品', 500, 320, '2009-09-11'); INSERT INTO Product VALUES ('0003', '运动T恤', '衣服', 4000, 2800, NULL); INSERT INTO Product VALUES ('0004', '菜刀', '厨房用具', 3000, 2800, '2009-09-20'); INSERT INTO Product VALUES ('0005', '高压锅', '厨房用具', 6800, 5000, '2009-01-15'); INSERT INTO Product VALUES ('0006', '叉子', '厨房用具', 500, NULL, '2009-09-20'); INSERT INTO Product VALUES ('0007', '擦菜板', '厨房用具', 880, 790, '2008-04-28'); INSERT INTO Product VALUES ('0008', '圆珠笔', '办公用品', 100, NULL, '2009-11-11'); COMMIT; 上面的代码对于不同的RDBMS会略有不同，例如SQL Server,Postgre SQL中开始指令为BEGIN TRANSACTION；MySQL中开始指令为START TRANSACTION；Oracle和DB2中不需要开始指令，直接用INSERT INTO &lt;表名&gt; VALUES (&lt;内容&gt;);开始。 1.3.4 修改表名 如果在匆忙中将Product输成了Poduct，又输入进了大量数据时，删除表再创建并输入数据会非常麻烦。大部分RDBMS中都提供了RENAME 指令来修改表名： #将表名Poduct修改为Product #Oracle,PostgreSQL ALTER TABLE Poduct RENAME TO Product; #DB2,MySQL RENAME TABLE Poduct TO Product; #SQL Server sp_rename 'Poduct', 'Product' 不同的RDBMS的RENAME指令的使用方法一般都不同，但都是按照修改前、修改后的名字来指定表名的。 今天学了第一章一些基础概念和一些基础操作，明天开始进入第二章：查询基础。同时，这些基础概念到后面的章节都会专门学习~ ","link":"https://wangykonne.github.io/post/sql-xue-xi-bi-ji-yi/"},{"title":"12.10 实习面经","content":" 面试公司：上海1药网股份有限公司 时长：约90分钟 结果：通过 面试题（一面）（应该是技术小哥来面试，很硬核的专业知识） Q1：详细介绍项目内容和具体算法的细节。 A1：（问到了很多模型细节方面的处理：如特征工程？现实意义？怎么评估模型？感觉回答的不是很好，被指出了很多待改进的地方） Q2：讲一下随机森林和决策树的区别？ A2：（概念问题，简而言之随机森林是决策树的一种bootstrap集成算法，采用自举样本、随机个特征同时进行多棵树的构建，最后把结果综合） Q3：接Q2，集成算法大体分为两种，一种就是你刚说的bootstrap，还有一种叫boosting，你了解过boosting的代表算法吗？ A3：（由于怕面试官考到细节知识和实现原理，我只说了听过Adaboost和Xgboost，具体原理还在学习中，毕竟还是知道多少说多少比较好） Q4：你觉得在数据挖掘的过程中，选择什么模型重要吗？ A4：（其实不是很懂面试官想问什么，我回答的是有一定重要程度，但面试官的答案是特征工程和如何获得干净的数据更重要，但他也没问哪个重要这种问题，不然我肯定也会说特征工程更重要...） Q5：你觉得数据挖掘中得到的变量重要性（因为在项目里提及过）在实际中应该怎么使用？ A5：（这里有点小卡壳，我回答的是可以重点关注这些指标，这些指标的高低可能会对预测变量有毕竟明显的影响，但面试官马上就问：那怎么衡量什么是高低呢？我就呆住.jpg了，确实没考虑这种问题，只好说视实际问题定...） Q6：在分类问题预测变量比例失衡下，accuracy还是一个科学的指标吗？你还知道哪些评估指标？ A6：（比较基础的理论，accuracy在比例失衡下不是个好的评估标准，可以采用召回率recall、精准度、f1分数、auc-roc值作为评估指标） Q7：SQL习题，有一个电商的仓库表，记录了省份、商品名、销售额。怎么查询各个省份销售量top10的商品（面试官表示不考虑销量相同的情况）？ A7：（说实话这道题不难，我写的是用rank窗口函数，partition by省份，order by销售额 desc就可以按省份分割并按销售额降序排列，最后使用where rank列的别名 &lt;=10即可。但一开始犯傻想用limit取10条，结果面试官提醒了一下这样只能取10条而不是每个省10条才用了where，实在是太弱了😭） 面试题（二面）（感觉是数据科学组的leader来面，虽然没问专业性特别强的问题，但气场很足，问的都是我的规划之类的） Q1：本科和研究生学了哪些统计学相关的课？ A1：（其实我本科真正和统计沾边的课只有概统和多元统计，其他的都是纯数的课，所以估计面试官也问不到什么知识，只问了研究生阶段的数据挖掘课一般学啥做啥） Q2：接触了数据科学后，你比较喜欢数分类的工作还是数据挖掘类的工作呢？以后的职业规划是怎样的？ A2：（其实说真的，我个人倾向于数分类的工作，毕竟我代码方面真的挺薄弱的，而且本科学算法与数据结构时候的痛苦现在还记得，可能实在是不太适合，不然我考研就跨CS了😭职业规划其实是想去自己喜欢的行业工作，比如一些游戏公司、b站这些我自己感兴趣的年轻领域，唉也不知道明年能不能实现Orz） Q3：自己对数据科学实习的工作预期是怎样的？ A3：（我回答的是，希望能在实习中得到锻炼，提高自己的coding能力和分析能力，而不是操作办公软件打杂。确实，这点我说的很直白，毕竟如果只是打杂当廉价劳动力而没有提升自己，那纯属浪费时间） Q4：介绍环节，讲了下公司数据科学团队的构成和日常工作 Q5：反问环节 A5：（①实习生的日常工作，我一直很关心这点，因为不想进来当Excel boy；②需要学习别的新软件吗？面试官说一般用python和SQL和R，可视化有时会用些BI软件） 面试题（三面）（普通的HR面，很轻松，聊天式） Q1：一些基本问题，感觉就像打招呼一样，例如：老家哪里的，是不是独生子女之类的... A1：（略） Q2：看到我是厦大的后，问我在厦大和交大的学习生活体验有什么不同？ A2：（我回答的大致意思是：大佬太多，我是乐色，以上🙃） Q3：如果来实习通勤大概多久？能坚持下来吗？ A3：（公司在张江高科，经典程序员之家，大概通勤90多分钟，挺远的。当然得回答能坚持下来） Q4：预期的实习薪资多少？ A4：（app上写的信息是200，所以我也回答的是200） Q5：有了解过公司吗？ A5：（没提前准备，只知道是卖药的公司，后面查了下，类似医药界的淘宝，还挺大的） Q6：为什么想实习？ A6：（锻炼自己解决实习问题的能力，同时实习也是职业规划上重要的一环！） Q7：用两个负面词语形容自己的话，你会选哪两个？为什么？ A7：（①内向不善沟通，②好强但又菜Orz） Q8：反问环节 A8：（问了下工作时间，有没有午饭。回答是早九晚六，午休一小时，没有午饭但有晚饭但晚饭要7点，啊这，经典诱惑员工加班！可恶！） 心得体会 这次面试的岗位叫数据科学实习生，听名字就能知道，偏挖掘一点，所以在心中的地位比任意门低了一点。尽管公司真的很大（独栋四层办公楼），而且也是上市公司前景也还不错，只是不是心中理想的行业吧（话说我在说什么，人家还没决定要收留我呢呜呜呜！）。目前总共面试两次，刚好就是一次数分一次数据挖掘，感受到的区别还是很大的，面数据挖掘岗还是一定要把自己写的项目全方位准备，基本面试官出题也就是从你的介绍中找出题点，所以要争取把项目上的所有可能的知识点尽可能全部准备。 ","link":"https://wangykonne.github.io/post/129-shi-xi-mian-jing-qi-er/"},{"title":"12.9 实习面经","content":" 面试公司：上海任意门科技有限公司 时长：约40分钟 结果：未知 面试题 Q1：就简历问了些项目的具体内容和工作 A1：（简历上的项目是研一上学期数据挖掘课的大作业，我把自己做的内容和工作都说明清楚就结束了，可能因为是商业数分类的岗位，没有问太多这方面的东西） Q2：你觉得数据分析和数据挖掘岗位有什么区别？ A2：（区别还是挺大的，自己答得挺顺的所以不记得具体说了啥，总之大概就是一个偏技术与理论一个偏产品和商业思维的区别） Q3：公司的核心产品是Soul APP，你觉得Soul APP的产品经理和分析团队每天需要观测哪些指标来分析产品是否有异常呢？ A3：（直击知识盲区，现场开始胡言乱语，我的回答是活跃用户、发动态数量这些基本的数据。最后面试官提了一个指标叫次流：表示第一天活跃的用户第二天还活跃的比例。涨姿势了！） Q4：Soul不同于微博，它的匿名性给了它一个去中心化产品的定位，你觉得数据上如何反应这种去中心化呢？ A4：（彻底懵圈，如果是Q3还能说点东西这道题就真的是硬编了...最后也没答到点上QAQ😭，面试官也没给答案，估计是觉得说了我也听不懂吧Orz） Q5：介绍一下SQL的窗口函数有哪些？ A5：（只回答了rank,dense_rank,row_number和聚合函数，面试官给我补充了lead和lag函数） Q6：说一下rank,dense_rank,row_number三者的区别？ A6：（比较简单，rank同次序会跳数，dense_rank同次序不会跳数，row_number不能同次序） Q7：紧接Q6，既然row_number不能同次序，那如果有两行完全一样谁前谁后呢？ A7：（我回答是按照主键或者索引定序，看面试官的表情应该是说对了） Q8：介绍一下内联结外联结和全联结 A8：（很简单的概念题，但是太紧张一开始把全联结说成交叉联结的定义了，呜呜呜😭） Q9：union和union all的区别？union可以对两个表中列名不同但数量相同对应数据类型也相同相关限制也相同数据含义也相同的列使用吗？ A9：（区别是是否对数据去重；可以使用） Q10：SQL题，一张表active_user，两列分别为用户uid和活跃时间（YYYY-MM-DD），求某一天的次流？ A10：（这道题我用了太多子查询被面试官说太麻烦，解答是将表active_user按uid左联结自己，查询两次活跃时间差为1天且活跃时间包括题干中的“某一天”的记录，最后select count(uid)，再除于某一天的前一天的活跃用户即可） Q11：反问环节 A11：（问了些有关工作内容的问题） 心得体会 公司环境还是很好的，很有年轻互联网公司内味。面试官也很Nice，回答不上商业的哪些题的时候他一直在提示我，虽然还是没说上来TAT。地理位置还是挺远的，一个半小时地铁才能到。工作内容主要是用SQL、Python进行数据分析，偶尔会进行数据挖掘，然后用Tableau进行数据可视化，写分析报告之类的。不过一般商业数分也都是这些活吧，只能说自己这方面的思维能力还要加强呀~ ","link":"https://wangykonne.github.io/post/129-shi-xi-mian-jing/"},{"title":"Hello World","content":" 成年人的第一个博客 经过两天的不懈努力，wyk终于把小站搭建好了，这几天真是被这种问题给整晕了😭顺便给其他想搭建github pages的同学一点人生经验：如果你用了Gridea渲染后github pages访问变得奇慢无比，请立即去github下载个靠谱的新主题！！ 没错，就是这个小小的问题困扰了我好几天（恼），我甚至在国内和国外都买了个域名，就差买个服务器了...马上考试和各种ddl都要来了，而我这几天都在整这个啥都没看😭。不说了，预计忙完这一阵子才会更新（或许想摸鱼的时候会搬运一些从前写的东西。 路漫漫其修远兮 建立这个小站呢，主要还是想监督自己学习，毕竟自己以前学习从来不做笔记，导致本科学过的很多东西如今都忘得差不多了。开学后受到同学的影响，开始试着写写笔记，然后发现写学习笔记其实是一种效率很高的办法。所以，为了督促自己学习，同时又能强化记忆，准备把这里作为自己的小图书馆👨‍🎓，短期目标是顺利通过期末和找到实习，长期目标是顺利毕业成为打工人👨‍💻。 let's start!（我真是High到不行啊！） ","link":"https://wangykonne.github.io/post/hello-world/"},{"title":"关于","content":" 欢迎来到我的小站呀，很高兴遇见你！🤝 🏠 关于本站 其实一直以来都有建个主页的想法，但碍于自己不会前端技术只好作罢。直到在知乎上看到了Gridea，不得不说使用起来还是很方便的👍。目前计划是在空闲时候整理自己从前的学习笔记并放到Pages上来，当然了，以后学习的新东西也会整理好上传。除此之外，毕竟是属于自己的小站，当然也会记录一些生活啊学习方面的碎碎念吧。总之就是这样，路漫漫其修远兮，希望自己空闲时刻能坚持更新吧~ 👨‍💻 博主是谁 关键词：数学专业秃头学生，小镇做题家，国家级摸鱼运动员，新垣结衣圈外男友（？ ⛹ 兴趣爱好 打游戏（Arknights，联盟），看动漫，睡觉 📬 联系我呀 Github指路：wangykonne；微博指路：@-Kraiyyn ","link":"https://wangykonne.github.io/post/about/"}]}